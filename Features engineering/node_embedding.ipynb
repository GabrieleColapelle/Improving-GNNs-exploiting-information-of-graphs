{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aafb8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dgl\n",
    "import pandas as pd\n",
    "import powerlaw\n",
    "from dgl import LaplacianPE\n",
    "from dgl import RandomWalkPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b0f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb\n",
    "%run model_base.ipynb\n",
    "%run communities.ipynb\n",
    "%run fastRP_impl.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0683f",
   "metadata": {},
   "source": [
    "## DBLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77753634",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Node embedding computation via FastRP and add embedding as node feature'''\n",
    "def fastRP_emb_DBLP(hg):\n",
    "    hg2 = copy.deepcopy(hg)\n",
    "    #find all actor of a film\n",
    "    transform = AddMetaPaths({\n",
    "    #'apa': [('author', 'ap', 'paper'),('paper', 'pa', 'author')],\n",
    "    #'pap': [('paper', 'pa', 'author'),('author','ap','paper')],\n",
    "    #'ptp': [('paper', 'pt', 'term'),('term','tp','paper')],\n",
    "    'tpt': [('term', 'tp', 'paper'),('paper','pt','term')],\n",
    "    #'pcp': [('paper', 'pc', 'conf'),('conf','cp','paper')],\n",
    "    #'cpc': [('conf', 'cp', 'paper'),('paper','pc','conf')]\n",
    "    })\n",
    "    \n",
    "    hg3 = transform(hg2)\n",
    "    g = dgl.to_homogeneous(hg3)\n",
    "    nxg = g.to_networkx()\n",
    "    n = nxg.to_undirected()\n",
    "    A = nx.adjacency_matrix(nxg)\n",
    "\n",
    "    prefix = 'result/blog'\n",
    "    conf = {\n",
    "            'projection_method': 'sparse',\n",
    "            'input_matrix': 'trans',\n",
    "            'weights': [0, 1.0, 3.0],\n",
    "            'normalization': False,\n",
    "            'dim': 18,\n",
    "            'alpha': 1.0,\n",
    "            'C': 1.0\n",
    "        }\n",
    "    emb_filename = get_emb_filename(prefix, conf)\n",
    "\n",
    "    U = fastrp_wrapper(A, conf)\n",
    "    \n",
    "    \n",
    "    authors = U[0:4057]\n",
    "    confs = U[4057:4077]\n",
    "    papers = U[4077:18405]\n",
    "    terms = U[18405:26128]\n",
    "    \n",
    "    author = torch.FloatTensor(authors)\n",
    "    paper = torch.FloatTensor(papers)\n",
    "    conf = torch.FloatTensor(confs)\n",
    "    term = torch.FloatTensor(terms)\n",
    "    \n",
    "    \n",
    "    tupl_au = (hg.nodes[\"author\"].data['feat'] ,author)\n",
    "    \n",
    "    author = torch.cat(tupl_au,1)\n",
    "    \n",
    "    hg.nodes[\"author\"].data['feat'] =  author\n",
    "    hg.nodes[\"paper\"].data['feat'] =  paper\n",
    "    hg.nodes[\"conf\"].data['feat'] =  conf\n",
    "    hg.nodes[\"term\"].data['feat'] =  term\n",
    "            \n",
    "    return hg \n",
    "\n",
    "'''Positional encoding via RandomWalk and add it as node feature'''\n",
    "def RW_emb_DBLP(hg,dim):\n",
    "    hg2 = copy.deepcopy(hg)\n",
    "    #find all actor of a film\n",
    "    transform = AddMetaPaths({\n",
    "    #'authors': [('author', 'ap', 'paper'),('paper', 'pa', 'author')],\n",
    "    'papers': [('paper', 'pa', 'author'),('author','ap','paper')],\n",
    "    'papers': [('paper', 'pt', 'term'),('term','tp','paper')],\n",
    "    #'terms': [('term', 'tp', 'paper'),('paper','pt','term')],\n",
    "    'papers': [('paper', 'pc', 'conf'),('conf','cp','paper')],\n",
    "    #'confs': [('conf', 'cp', 'paper'),('paper','pc','conf')]\n",
    "    })\n",
    "    \n",
    "    new_g = transform(hg2)\n",
    "    #new_g1 = new_g.edge_type_subgraph(['authors'])\n",
    "    new_g2 = new_g.edge_type_subgraph(['papers'])\n",
    "    #new_g3 = new_g.edge_type_subgraph(['terms'])\n",
    "    #new_g4 = new_g.edge_type_subgraph(['confs'])\n",
    "    \n",
    "    transform1 = RandomWalkPE(k=dim)\n",
    "    #g1 = transform1(new_g1)\n",
    "    #U1 = g1.ndata['PE']\n",
    "    \n",
    "    g2 = transform1(new_g2)\n",
    "    U2 = g2.ndata['PE']\n",
    "    \n",
    "    #g3 = transform1(new_g3)\n",
    "    #U3 = g3.ndata['PE']\n",
    "    \n",
    "    #g4 = transform1(new_g4)\n",
    "    #U4 = g4.ndata['PE']\n",
    "    \n",
    "    #tupl_au = (hg.nodes[\"author\"].data['feat'] ,U1)\n",
    "    tupl_pa = (hg.nodes[\"paper\"].data['feat'] ,U2)\n",
    "    #tupl_te = (hg.nodes[\"term\"].data['feat'] ,U3)\n",
    "    #tupl_co = (hg.nodes[\"conf\"].data['feat'] ,U4)\n",
    "    \n",
    "    #author = torch.cat(tupl_au,1)\n",
    "    paper = torch.cat(tupl_pa,1)\n",
    "    #term = torch.cat(tupl_te,1)\n",
    "    #conf = torch.cat(tupl_co,1)\n",
    "    \n",
    "    #hg.nodes[\"author\"].data[\"feat\"] = author\n",
    "    hg.nodes[\"paper\"].data[\"feat\"] = paper\n",
    "    #hg.nodes[\"term\"].data[\"feat\"] = term\n",
    "    #hg.nodes[\"conf\"].data[\"feat\"] = conf\n",
    "         \n",
    "    return hg \n",
    "\n",
    "'''Positional encoding via Laplacian Positional Encoding and add it as node feature'''\n",
    "def LPE_emb_DBLP(hg,dim):\n",
    "    hg2 = copy.deepcopy(hg)\n",
    "    #find all actor of a film\n",
    "    transform = AddMetaPaths({\n",
    "    #'authors': [('author', 'ap', 'paper'),('paper', 'pa', 'author')],\n",
    "    #'papers': [('paper', 'pa', 'author'),('author','ap','paper')],\n",
    "    #'papers': [('paper', 'pt', 'term'),('term','tp','paper')],\n",
    "    #'terms': [('term', 'tp', 'paper'),('paper','pt','term')],\n",
    "    'papers': [('paper', 'pc', 'conf'),('conf','cp','paper')],\n",
    "    'confs': [('conf', 'cp', 'paper'),('paper','pc','conf')]\n",
    "    })\n",
    "    \n",
    "    new_g = transform(hg2)\n",
    "    #new_g1 = new_g.edge_type_subgraph(['authors'])\n",
    "    new_g2 = new_g.edge_type_subgraph(['papers'])\n",
    "    #new_g3 = new_g.edge_type_subgraph(['terms'])\n",
    "    new_g4 = new_g.edge_type_subgraph(['confs'])\n",
    "    \n",
    "    transform1 = LaplacianPE(k=dim)\n",
    "    #g1 = transform1(new_g1)\n",
    "    #U1 = g1.ndata['PE']\n",
    "    \n",
    "    g2 = transform1(new_g2)\n",
    "    U2 = g2.ndata['PE']\n",
    "    \n",
    "    #g3 = transform1(new_g3)\n",
    "    #U3 = g3.ndata['PE']\n",
    "    \n",
    "    g4 = transform1(new_g4)\n",
    "    U4 = g4.ndata['PE']\n",
    "    \n",
    "    #tupl_au = (hg.nodes[\"author\"].data['feat'] ,U1)\n",
    "    tupl_pa = (hg.nodes[\"paper\"].data['feat'] ,U2)\n",
    "    #tupl_te = (hg.nodes[\"term\"].data['feat'] ,U3)\n",
    "    tupl_co = (hg.nodes[\"conf\"].data['feat'] ,U4)\n",
    "    \n",
    "    #author = torch.cat(tupl_au,1)\n",
    "    paper = torch.cat(tupl_pa,1)\n",
    "    #term = torch.cat(tupl_te,1)\n",
    "    conf = torch.cat(tupl_co,1)\n",
    "    \n",
    "    #hg.nodes[\"author\"].data[\"feat\"] = author\n",
    "    hg.nodes[\"paper\"].data[\"feat\"] = paper\n",
    "    #hg.nodes[\"term\"].data[\"feat\"] = term\n",
    "    hg.nodes[\"conf\"].data[\"feat\"] = conf\n",
    "    print(hg.nodes[\"conf\"].data[\"feat\"][0])\n",
    "    \n",
    "            \n",
    "    return hg \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec02044",
   "metadata": {},
   "source": [
    "## ACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03be495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastRP_emb_ACM(hg):\n",
    "    hg2 = copy.deepcopy(hg)\n",
    "    #find all actor of a film\n",
    "    transform = AddMetaPaths({\n",
    "    'pap': [('paper', 'pa', 'author'),('author', 'ap', 'paper')],\n",
    "    #'pfp': [('paper', 'pf', 'field'),('field','fp','paper')],\n",
    "    #'apa': [('author', 'ap', 'paper'),('paper','pa','author')],\n",
    "    #'fpf': [('field', 'fp', 'paper'),('paper','pf','field')]\n",
    "    \n",
    "    })\n",
    "    \n",
    "    hg3 = transform(hg2)\n",
    "    g = dgl.to_homogeneous(hg3)\n",
    "    nxg = g.to_networkx()\n",
    "    n = nxg.to_undirected()\n",
    "    A = nx.adjacency_matrix(nxg)\n",
    "\n",
    "    prefix = 'result/blog'\n",
    "    conf = {\n",
    "            'projection_method': 'sparse',\n",
    "            'input_matrix': 'trans',\n",
    "            'weights': [0, 1.0, 1.0, 58.69],\n",
    "            'normalization': False,\n",
    "            'dim': 4,\n",
    "            'alpha': -0.10,\n",
    "            'C': 1.0\n",
    "        }\n",
    "    emb_filename = get_emb_filename(prefix, conf)\n",
    "\n",
    "    U = fastrp_wrapper(A, conf)\n",
    "    \n",
    "    \n",
    "    authors = U[:17351]\n",
    "    fields = U[17351:17423]\n",
    "    papers = U[17423:21449]\n",
    "    \n",
    " \n",
    "    author = torch.FloatTensor(authors)\n",
    "    paper = torch.FloatTensor(papers)\n",
    "    field = torch.FloatTensor(fields)\n",
    "    \n",
    "    \n",
    "    tupl_pa = (hg.nodes[\"paper\"].data['feat'] ,paper)\n",
    "    \n",
    "    paper = torch.cat(tupl_pa,1)\n",
    "    \n",
    "    hg.nodes[\"author\"].data['feat'] =  author\n",
    "    hg.nodes[\"paper\"].data['feat'] =  paper\n",
    "    hg.nodes[\"field\"].data['feat'] =  field\n",
    "            \n",
    "    return hg\n",
    "\n",
    "\n",
    "def LPE_emb_ACM(hg,dim):\n",
    "    transform = AddMetaPaths({\n",
    "    'authors': [('paper', 'pf', 'field'),('field', 'fp', 'paper')],\n",
    "    'authors': [('paper', 'pa', 'author'),('author','ap','paper')],\n",
    "    #'same_paper' : [('author','ap','paper'),('paper','pa','author')],\n",
    "    #'same_field' : [('field','fp','paper'),('paper','pf','field')]   \n",
    "\n",
    "    })\n",
    "    new_g = transform(hg)\n",
    "    new_g1 = new_g.edge_type_subgraph(['authors'])\n",
    "    #new_g2 = new_g.edge_type_subgraph(['same_paper'])\n",
    "    #new_g3 = new_g.edge_type_subgraph(['same_field'])\n",
    "    \n",
    "    transform1 = LaplacianPE(k=dim)\n",
    "    g1 = transform1(new_g1)\n",
    "    U1 = g1.ndata['PE']\n",
    "    \n",
    "    #g2 = transform1(new_g2)\n",
    "    #U2 = g2.ndata['PE']\n",
    "    \n",
    "    #g3 = transform1(new_g3)\n",
    "    #U3 = g3.ndata['PE']\n",
    "    \n",
    "    tupl_pa = (hg.nodes[\"paper\"].data['feat'] ,U1)\n",
    "    #tupl_au = (hg.nodes[\"author\"].data['feat'] ,U2)\n",
    "    #tupl_fi = (hg.nodes[\"field\"].data['feat'] ,U3)\n",
    "    \n",
    "    paper = torch.cat(tupl_pa,1)\n",
    "    #author = torch.cat(tupl_au,1)\n",
    "    #field = torch.cat(tupl_fi,1)\n",
    "    \n",
    "    hg.nodes[\"paper\"].data[\"feat\"] = paper\n",
    "    #hg.nodes[\"author\"].data[\"feat\"] = author\n",
    "    #hg.nodes[\"field\"].data[\"feat\"] = field\n",
    "    \n",
    "    return hg\n",
    "\n",
    "def RW_emb_ACM(hg,dim):\n",
    "    transform = AddMetaPaths({\n",
    "    'authors': [('paper', 'pf', 'field'),('field', 'fp', 'paper')],\n",
    "    'authors': [('paper', 'pa', 'author'),('author','ap','paper')],\n",
    "    'same_paper' : [('author','ap','paper'),('paper','pa','author')],\n",
    "    'same_field' : [('field','fp','paper'),('paper','pf','field')]   \n",
    "\n",
    "    })\n",
    "    new_g = transform(hg)\n",
    "    new_g1 = new_g.edge_type_subgraph(['authors'])\n",
    "    #new_g2 = new_g.edge_type_subgraph(['same_paper'])\n",
    "    #new_g3 = new_g.edge_type_subgraph(['same_field'])\n",
    "    \n",
    "    transform1 = RandomWalkPE(k=dim)\n",
    "    g1 = transform1(new_g1)\n",
    "    U1 = g1.ndata['PE']\n",
    "    \n",
    "    #g2 = transform1(new_g2)\n",
    "    #U2 = g2.ndata['PE']\n",
    "    \n",
    "    #g3 = transform1(new_g3)\n",
    "    #U3 = g3.ndata['PE']\n",
    "    \n",
    "    tupl_pa = (hg.nodes[\"paper\"].data['feat'] ,U1)\n",
    "    #tupl_au = (hg.nodes[\"author\"].data['feat'] ,U2)\n",
    "    #tupl_fi = (hg.nodes[\"field\"].data['feat'] ,U3)\n",
    "    \n",
    "    paper = torch.cat(tupl_pa,1)\n",
    "    #author = torch.cat(tupl_au,1)\n",
    "    #field = torch.cat(tupl_fi,1)\n",
    "    \n",
    "    hg.nodes[\"paper\"].data[\"feat\"] = paper\n",
    "    #hg.nodes[\"author\"].data[\"feat\"] = author\n",
    "    #hg.nodes[\"field\"].data[\"feat\"] = field\n",
    "    \n",
    "    print(len(hg.nodes[\"author\"].data[\"feat\"][0]))\n",
    "\n",
    "    return hg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a8f26",
   "metadata": {},
   "source": [
    "#### FastRp for Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afbd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastRP_emb_ACM_opt(hg,conf,dim):\n",
    "    hg2 = copy.deepcopy(hg)\n",
    "    #find all actor of a film\n",
    "    #transform = AddMetaPaths({\n",
    "    #'pap': [('paper', 'pa', 'author'),('author', 'ap', 'paper')],\n",
    "    #'pfp': [('paper', 'pf', 'field'),('field','fp','paper')],\n",
    "    #'apa': [('author', 'ap', 'paper'),('paper','pa','author')],\n",
    "    #'fpf': [('field', 'fp', 'paper'),('paper','pf','field')]\n",
    "    \n",
    "    #})\n",
    "    \n",
    "    #hg3 = transform(hg2)\n",
    "    g = dgl.to_homogeneous(hg2)\n",
    "    nxg = g.to_networkx()\n",
    "    n = nxg.to_undirected()\n",
    "    A = nx.adjacency_matrix(nxg)\n",
    "    \n",
    "    prefix = 'result/blog'\n",
    "    \n",
    "    emb_filename = get_emb_filename(prefix, conf)\n",
    "\n",
    "    U = fastrp_wrapper(A, conf)\n",
    "    \n",
    "    authors = U[:17351]\n",
    "    fields = U[17351:17423]\n",
    "    papers = U[17423:21449]\n",
    "    \n",
    " \n",
    "    author = torch.FloatTensor(authors)\n",
    "    paper = torch.FloatTensor(papers)\n",
    "    field = torch.FloatTensor(fields)\n",
    "    \n",
    "    \n",
    "    tupl_pa = (hg.nodes[\"paper\"].data['feat'] ,paper)\n",
    "    \n",
    "    paper = torch.cat(tupl_pa,1)\n",
    "    \n",
    "    hg.nodes[\"author\"].data['feat'] =  author\n",
    "    hg.nodes[\"paper\"].data['feat'] =  paper\n",
    "    hg.nodes[\"field\"].data['feat'] =  field\n",
    "            \n",
    "    return hg "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361fc2bb",
   "metadata": {},
   "source": [
    "## IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastRP_emb_imdb(hg):\n",
    "    hg2 = copy.deepcopy(hg)\n",
    "    #find all actor of a film\n",
    "    transform = AddMetaPaths({\n",
    "    'mam': [('movie', 'ma', 'actor'),('actor', 'am', 'movie')],\n",
    "    'ama': [('actor', 'am', 'movie'),('movie','ma','actor')],\n",
    "    'dmd': [('director', 'dm', 'movie'),('movie','md','director')],\n",
    "    'mdm': [('movie', 'md', 'director'),('director','dm','movie')]\n",
    "    })\n",
    "    \n",
    "    hg3 = transform(hg2)\n",
    "    g = dgl.to_homogeneous(hg3)\n",
    "    nxg = g.to_networkx()\n",
    "    n = nxg.to_undirected()\n",
    "    A = nx.adjacency_matrix(nxg)\n",
    "\n",
    "    prefix = 'result/blog'\n",
    "    conf = {\n",
    "            'projection_method': 'sparse',\n",
    "            'input_matrix': 'trans',\n",
    "            'weights': [0, 1.0, 1.0],\n",
    "            'normalization': False,\n",
    "            'dim': 18,\n",
    "            'alpha': 1.0,\n",
    "            'C': 1.0\n",
    "        }\n",
    "    emb_filename = get_emb_filename(prefix, conf)\n",
    "\n",
    "    U = fastrp_wrapper(A, conf)\n",
    "    \n",
    "    \n",
    "    actors = U[:5257]\n",
    "    directors = U[5257:7338]\n",
    "    movies = U[7338:11616]\n",
    "    \n",
    " \n",
    "    actor = torch.FloatTensor(actors)\n",
    "    director = torch.FloatTensor(directors)\n",
    "    movie = torch.FloatTensor(movies)\n",
    "        \n",
    "    tupl_mo = (hg.nodes[\"movie\"].data['feat'] ,movie)\n",
    "    \n",
    "    movie = torch.cat(tupl_mo,1)\n",
    "    \n",
    "    hg.nodes[\"actor\"].data['feat'] =  actor\n",
    "    hg.nodes[\"director\"].data['feat'] =  director\n",
    "    hg.nodes[\"movie\"].data['feat'] =  movie\n",
    "    print(len(hg.nodes[\"movie\"].data['feat']))\n",
    "            \n",
    "    return hg \n",
    "\n",
    "def LPE_emb_imdb(hg,dim):\n",
    "    hg2 = copy.deepcopy(hg)\n",
    "    transform = AddMetaPaths({\n",
    "    'movies': [('movie', 'ma', 'actor'),('actor', 'am', 'movie')],\n",
    "    'movies': [('movie', 'md', 'director'),('director','dm','movie')],\n",
    "    #'same_movie' : [('actor','am','movie'),('movie','ma','actor')],\n",
    "    #'same_director' : [('director','dm','movie'),('movie','md','director')]   \n",
    "\n",
    "    })\n",
    "    new_g = transform(hg2)\n",
    "    new_g1 = new_g.edge_type_subgraph(['movies'])\n",
    "    \n",
    "    #new_g2 = new_g.edge_type_subgraph(['same_movie'])\n",
    "    #new_g3 = new_g.edge_type_subgraph(['same_director'])\n",
    "    \n",
    "    transform1 = LaplacianPE(k=dim)\n",
    "    \n",
    "    g1 = transform1(new_g1)\n",
    "    U1 = g1.ndata['PE']\n",
    "    \n",
    "    #g2 = transform1(new_g2)\n",
    "    #U2 = g2.ndata['PE']\n",
    "    \n",
    "    #g3 = transform1(new_g3)\n",
    "    #U3 = g3.ndata['PE']\n",
    "    \n",
    "        \n",
    "    tupl_mo = (hg.nodes[\"movie\"].data['feat'] ,U1)\n",
    "    #tupl_ac = (hg.nodes[\"actor\"].data['feat'] ,U2)\n",
    "    #tupl_di = (hg.nodes[\"director\"].data['feat'] ,U3)\n",
    "    \n",
    "    movie = torch.cat(tupl_mo,1)\n",
    "    #actor = torch.cat(tupl_ac,1)\n",
    "    #director = torch.cat(tupl_di,1)\n",
    "    \n",
    "    hg.nodes[\"movie\"].data[\"feat\"] = movie\n",
    "    #hg.nodes[\"actor\"].data[\"feat\"] = actor\n",
    "    #hg.nodes[\"director\"].data[\"feat\"] = director\n",
    "    \n",
    "    print(hg.nodes[\"movie\"].data[\"feat\"])\n",
    "    print(hg.nodes[\"actor\"].data[\"feat\"])\n",
    "    print(hg.nodes[\"director\"].data[\"feat\"])\n",
    "       \n",
    "    return hg\n",
    "\n",
    "\n",
    "\n",
    "def RW_emb_imdb(hg,dim):\n",
    "    hg2 = copy.deepcopy(hg)\n",
    "    transform = AddMetaPaths({\n",
    "    'movies': [('movie', 'ma', 'actor'),('actor', 'am', 'movie')],\n",
    "    #'movies': [('movie', 'md', 'director'),('director','dm','movie')],\n",
    "    #'same_movie' : [('actor','am','movie'),('movie','ma','actor')],\n",
    "    #'same_director' : [('director','dm','movie'),('movie','md','director')]   \n",
    "\n",
    "    })\n",
    "    new_g = transform(hg2)\n",
    "    new_g1 = new_g.edge_type_subgraph(['movies'])\n",
    "    \n",
    "    #new_g2 = new_g.edge_type_subgraph(['same_movie'])\n",
    "    #new_g3 = new_g.edge_type_subgraph(['same_director'])\n",
    "    \n",
    "    transform1 = RandomWalkPE(k=dim)\n",
    "\n",
    "    g1 = transform1(new_g1)\n",
    "    U1 = g1.ndata['PE']\n",
    "    \n",
    "    #g2 = transform1(new_g2)\n",
    "    #U2 = g2.ndata['PE']\n",
    "    \n",
    "    #g3 = transform1(new_g3)\n",
    "    #U3 = g3.ndata['PE']\n",
    "    \n",
    "        \n",
    "    tupl_mo = (hg.nodes[\"movie\"].data['feat'] ,U1)\n",
    "    #tupl_ac = (hg.nodes[\"actor\"].data['feat'] ,U2)\n",
    "    #tupl_di = (hg.nodes[\"director\"].data['feat'] ,U3)\n",
    "    \n",
    "    movie = torch.cat(tupl_mo,1)\n",
    "    #actor = torch.cat(tupl_ac,1)\n",
    "    #director = torch.cat(tupl_di,1)\n",
    "    \n",
    "    hg.nodes[\"movie\"].data[\"feat\"] = movie\n",
    "    #hg.nodes[\"actor\"].data[\"feat\"] = actor\n",
    "    #hg.nodes[\"director\"].data[\"feat\"] = director\n",
    "    \n",
    "    print(hg.nodes[\"movie\"].data[\"feat\"])\n",
    "    print(hg.nodes[\"actor\"].data[\"feat\"])\n",
    "    print(hg.nodes[\"director\"].data[\"feat\"])\n",
    "\n",
    "    \n",
    "    return hg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
