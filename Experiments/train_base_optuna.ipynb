{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b45601ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2566987f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "%run utils.ipynb\n",
    "%run model_com_embedding.ipynb\n",
    "%run communities.ipynb\n",
    "%run data.ipynb\n",
    "%run node_embedding.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b252124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_and_process(db):\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    DATASET = {\n",
    "        'acm': ACMDataset(),\n",
    "        'imdb': IMDbDataset(),\n",
    "        'dblp': DBLPFourAreaDataset()\n",
    "    }\n",
    "\n",
    "    set_random_seed(1)\n",
    "    data = DATASET[db]\n",
    "    g = data[0]\n",
    "    if data == DATASET['dblp']:\n",
    "        print(\"DBLP Dataset\")\n",
    "        g = get_degree_dblp(g)\n",
    "        g = get_triangle_count_dblp(g)\n",
    "        #g = get_PageRank_dblp(g)\n",
    "        #g = get_LCC_dblp(g)\n",
    "        g = fastRP_emb_dblp(g)\n",
    "        #g = RW_emb_dblp(g,2)\n",
    "        g = LPE_emb_dblp(g,2)\n",
    "        \n",
    "    elif data == DATASET['acm']:\n",
    "        print(\"ACM Dataset\")\n",
    "        #g = get_degree_acm(g)\n",
    "        g = get_degree_centrality_acm(g)\n",
    "        #g = get_triangle_count_acm(g)\n",
    "        #g = get_pageRank_acm(g)\n",
    "        #g = get_LCC_acm(g)\n",
    "        #g = fastRP_emb_acm(g)\n",
    "        g = RW_emb_ACM(g,2)\n",
    "        g = LPE_emb_ACM(g,2)\n",
    "        \n",
    "    elif data == DATASET['imdb']:\n",
    "        print(\"IMDb Dataset\")\n",
    "        #g = get_degree_imdb(g)\n",
    "        g = get_degree_centrality_imdb(g)\n",
    "        #g = get_triangle_count_imdb(g)\n",
    "        #g = get_pageRank_imdb(g)\n",
    "        #g = get_LCC_imdb(g)\n",
    "        #g = fastRP_emb_imdb(g)\n",
    "        g = RW_emb_imdb(g,2)\n",
    "        g = LPE_emb_imdb(g,2)\n",
    "    return data,g\n",
    "\n",
    "feat = \"feat\"\n",
    "\n",
    "        \n",
    "    \n",
    "def objective(trial):\n",
    "    import ast\n",
    "    mlflow.set_experiment(\"ACM_Layer_opt\")\n",
    "    experiment = mlflow.get_experiment_by_name(\"experiment name\")\n",
    "    the_last_loss = 1000\n",
    "    patience = 20\n",
    "    trigger_times = 0\n",
    "    #node type to predict\n",
    "    predict_ntype = data.predict_ntype\n",
    "    #dictionary containing node type and features\n",
    "    #lists containing labels, train-mask,val_mask and test-mask\n",
    "    labels = g.nodes[predict_ntype].data['label']\n",
    "    train_mask = g.nodes[predict_ntype].data['train_mask']\n",
    "    val_mask = g.nodes[predict_ntype].data['val_mask']\n",
    "    test_mask = g.nodes[predict_ntype].data['test_mask']\n",
    "       \n",
    "   \n",
    "    n_layer = trial.suggest_int('n_layer', 2, 4)\n",
    "    #dropout = define dropout rate range\n",
    "    #n_head = define n head range\n",
    "    \n",
    "    \n",
    "    if data.name == \"DBLP_four_area\":\n",
    "        get_com_Louvain_DBLP(g)\n",
    "        #get_com_Lpa_DBLP(g)\n",
    "        #get_com_Leiden_DBLP(g)\n",
    "        com_dict, num_com, com_dim_emb = get_com_info_DBLP() \n",
    "        \n",
    "    if data.name == \"imdb\":\n",
    "        \n",
    "        #get_com_Louvain_IMDb(g)\n",
    "        #get_com_LPA_IMDb(g)\n",
    "        get_com_Leiden_IMDb(g)\n",
    "        com_dict, num_com, com_dim_emb = get_com_info_IMDb()\n",
    "        \n",
    "    #if data.name == \"ACM\":\n",
    "        #get_com_LPA_ACM(g)\n",
    "        #get_com_Leiden_ACM(g)\n",
    "        #get_com_Louvain_ACM(g)  \n",
    "        #com_dict, num_com, com_dim_emb = get_com_info_ACM()\n",
    "    \n",
    "    features = {ntype: g.nodes[ntype].data[feat] for ntype in g.ntypes}\n",
    "        \n",
    "        \n",
    "    with mlflow.start_run():\n",
    "            #initialization of HGT model\n",
    "        model = HGT1(\n",
    "            {ntype: g.nodes[ntype].data[feat].shape[1] for ntype in g.ntypes},\n",
    "            256, data.num_classes, 8, g.ntypes, g.canonical_etypes,\n",
    "            predict_ntype, 3, 0.5\n",
    "        )\n",
    "        optimizer = optim.AdamW(model.parameters())\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, 0.005, total_steps=1000)\n",
    "        metrics = 'Epoch {:d} | Train Loss {:.4f} | Train Micro-F1 {:.4f} | Train Macro-F1 {:.4f}' \\\n",
    "                    ' | Val Micro-F1 {:.4f} | Val Macro-F1 {:.4f}' \n",
    "        #CHANGE       \n",
    "        warnings.filterwarnings('ignore', 'Setting attributes on ParameterDict is not supported')\n",
    "        epochs = 1000\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            # forward propagation by using all nodes\n",
    "            # reading the data from the file\n",
    "            logits = model(g,features)\n",
    "            #compute loss\n",
    "            loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "            valid_loss = F.cross_entropy(logits[val_mask], labels[val_mask])\n",
    "            # backward propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            #Total norm of the parameter gradients (viewed as a single vector).\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            #Get the train scores as (microf1,macrof1)\n",
    "            #print(emb(torch.LongTensor([0])))\n",
    "            train_scores = micro_macro_f1_score(logits[train_mask], labels[train_mask])\n",
    "            #Get the val scores as ((microf1,macrof1),val_loss)\n",
    "            val_scores = evaluate(model, g, features, labels, val_mask, micro_macro_f1_score)\n",
    "            # Early stopping\n",
    "            print(\"------------------\")\n",
    "            print('The current validation loss:', valid_loss.item())\n",
    "            \n",
    "            if valid_loss > the_last_loss:\n",
    "                trigger_times += 1\n",
    "                print('trigger times:', trigger_times)\n",
    "\n",
    "                if trigger_times >= patience:\n",
    "                    print('Early stopping!\\nStart to test process.')\n",
    "                    break\n",
    "                    print('Early stopping!\\nStart to test process.')        \n",
    "            else:\n",
    "                print('trigger times: 0')\n",
    "                trigger_times = 0\n",
    "                #save the best model\n",
    "                torch.save(model.state_dict(), 'best-model-parameters.pt')\n",
    "                #save the last validation loss aka the best validation loss\n",
    "                the_last_loss = valid_loss\n",
    "                #save the epoch during the best validation loss\n",
    "                the_last_epoch = epoch\n",
    "                #save the best \n",
    "                best_train_score = train_scores\n",
    "                best_val_score = val_scores[0]\n",
    "                best_val_loss = the_last_loss\n",
    "                #best_test = test_scores\n",
    "                \n",
    "            print(metrics.format(epoch, loss.item(), *train_scores, *val_scores[0]))\n",
    "\n",
    "        #load the best model\n",
    "        model.load_state_dict(torch.load('best-model-parameters.pt', map_location='cpu'))\n",
    "        #testing\n",
    "        test_scores, loss = evaluate(model, g, features, labels, test_mask, micro_macro_f1_score)\n",
    "        print('Test Micro-F1 {:.4f} | Test Macro-F1 {:.4f}'.format(*test_scores))\n",
    "        mlflow.log_param(\"stop_at_epoch\", epoch)\n",
    "        mlflow.log_param(\"best_at_epoch\", the_last_epoch)\n",
    "        mlflow.log_metric(\"loss_test\", loss)\n",
    "        mlflow.log_metric(\"loss_val\", best_val_loss)\n",
    "        mlflow.log_metric(\"train_Micro_f1\", best_train_score[0])\n",
    "        mlflow.log_metric(\"train_Macro_f1\", best_train_score[1])\n",
    "        mlflow.log_metric(\"test_Micro_f1\",test_scores[0])\n",
    "        mlflow.log_metric(\"test_Macro_f1\", test_scores[1])\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "#return a pair (F1_score, loss)\n",
    "def evaluate(model, g, features, labels, mask, score):\n",
    "    model.eval()\n",
    "    logits = model(g, features)\n",
    "    loss = F.cross_entropy(logits[mask], labels[mask])\n",
    "    return score(logits[mask], labels[mask]), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adf59c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "ACM Dataset\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-01 15:50:32,929]\u001b[0m A new study created in memory with name: no-name-80a7e363-a527-491e-97c1-e49a2f9e280a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "The current validation loss: 1.145439863204956\n",
      "trigger times: 0\n",
      "Epoch 0 | Train Loss 1.1324 | Train Micro-F1 0.3658 | Train Macro-F1 0.3430 | Val Micro-F1 0.4875 | Val Macro-F1 0.2185\n",
      "------------------\n",
      "The current validation loss: 1.0914907455444336\n",
      "trigger times: 0\n",
      "Epoch 1 | Train Loss 1.0599 | Train Micro-F1 0.4975 | Train Macro-F1 0.2567 | Val Micro-F1 0.4875 | Val Macro-F1 0.2185\n",
      "------------------\n",
      "The current validation loss: 1.015836238861084\n",
      "trigger times: 0\n",
      "Epoch 2 | Train Loss 0.9846 | Train Micro-F1 0.5175 | Train Macro-F1 0.3067 | Val Micro-F1 0.5138 | Val Macro-F1 0.2886\n",
      "------------------\n",
      "The current validation loss: 0.9300422072410583\n",
      "trigger times: 0\n",
      "Epoch 3 | Train Loss 0.9073 | Train Micro-F1 0.5733 | Train Macro-F1 0.4699 | Val Micro-F1 0.6775 | Val Macro-F1 0.6393\n",
      "------------------\n",
      "The current validation loss: 0.9283702373504639\n",
      "trigger times: 0\n",
      "Epoch 4 | Train Loss 0.8954 | Train Micro-F1 0.6100 | Train Macro-F1 0.5756 | Val Micro-F1 0.7450 | Val Macro-F1 0.7348\n",
      "------------------\n",
      "The current validation loss: 0.9110558032989502\n",
      "trigger times: 0\n",
      "Epoch 5 | Train Loss 0.8701 | Train Micro-F1 0.6362 | Train Macro-F1 0.6076 | Val Micro-F1 0.7612 | Val Macro-F1 0.7505\n",
      "------------------\n",
      "The current validation loss: 0.841399610042572\n",
      "trigger times: 0\n",
      "Epoch 6 | Train Loss 0.7866 | Train Micro-F1 0.7075 | Train Macro-F1 0.6924 | Val Micro-F1 0.7237 | Val Macro-F1 0.6956\n",
      "------------------\n",
      "The current validation loss: 0.8132385015487671\n",
      "trigger times: 0\n",
      "Epoch 7 | Train Loss 0.7616 | Train Micro-F1 0.7058 | Train Macro-F1 0.6702 | Val Micro-F1 0.6863 | Val Macro-F1 0.6290\n",
      "------------------\n",
      "The current validation loss: 0.783887505531311\n",
      "trigger times: 0\n",
      "Epoch 8 | Train Loss 0.7121 | Train Micro-F1 0.7242 | Train Macro-F1 0.6839 | Val Micro-F1 0.6913 | Val Macro-F1 0.6335\n",
      "------------------\n",
      "The current validation loss: 0.7127361297607422\n",
      "trigger times: 0\n",
      "Epoch 9 | Train Loss 0.6483 | Train Micro-F1 0.7392 | Train Macro-F1 0.7018 | Val Micro-F1 0.7325 | Val Macro-F1 0.6963\n",
      "------------------\n",
      "The current validation loss: 0.6445580124855042\n",
      "trigger times: 0\n",
      "Epoch 10 | Train Loss 0.5845 | Train Micro-F1 0.7817 | Train Macro-F1 0.7560 | Val Micro-F1 0.8050 | Val Macro-F1 0.7933\n",
      "------------------\n",
      "The current validation loss: 0.6056666970252991\n",
      "trigger times: 0\n",
      "Epoch 11 | Train Loss 0.5341 | Train Micro-F1 0.8263 | Train Macro-F1 0.8104 | Val Micro-F1 0.8600 | Val Macro-F1 0.8603\n",
      "------------------\n",
      "The current validation loss: 0.5899970531463623\n",
      "trigger times: 0\n",
      "Epoch 12 | Train Loss 0.4984 | Train Micro-F1 0.8713 | Train Macro-F1 0.8675 | Val Micro-F1 0.8838 | Val Macro-F1 0.8861\n",
      "------------------\n",
      "The current validation loss: 0.526496946811676\n",
      "trigger times: 0\n",
      "Epoch 13 | Train Loss 0.4446 | Train Micro-F1 0.8933 | Train Macro-F1 0.8921 | Val Micro-F1 0.8888 | Val Macro-F1 0.8917\n",
      "------------------\n",
      "The current validation loss: 0.5218451023101807\n",
      "trigger times: 0\n",
      "Epoch 14 | Train Loss 0.4160 | Train Micro-F1 0.9004 | Train Macro-F1 0.9004 | Val Micro-F1 0.8925 | Val Macro-F1 0.8949\n",
      "------------------\n",
      "The current validation loss: 0.45227620005607605\n",
      "trigger times: 0\n",
      "Epoch 15 | Train Loss 0.3634 | Train Micro-F1 0.9150 | Train Macro-F1 0.9143 | Val Micro-F1 0.8850 | Val Macro-F1 0.8867\n",
      "------------------\n",
      "The current validation loss: 0.4303523004055023\n",
      "trigger times: 0\n",
      "Epoch 16 | Train Loss 0.3448 | Train Micro-F1 0.9083 | Train Macro-F1 0.9066 | Val Micro-F1 0.8838 | Val Macro-F1 0.8845\n",
      "------------------\n",
      "The current validation loss: 0.40336108207702637\n",
      "trigger times: 0\n",
      "Epoch 17 | Train Loss 0.3032 | Train Micro-F1 0.9175 | Train Macro-F1 0.9157 | Val Micro-F1 0.8838 | Val Macro-F1 0.8844\n",
      "------------------\n",
      "The current validation loss: 0.3884270489215851\n",
      "trigger times: 0\n",
      "Epoch 18 | Train Loss 0.2826 | Train Micro-F1 0.9183 | Train Macro-F1 0.9167 | Val Micro-F1 0.8900 | Val Macro-F1 0.8910\n",
      "------------------\n",
      "The current validation loss: 0.333438903093338\n",
      "trigger times: 0\n",
      "Epoch 19 | Train Loss 0.2307 | Train Micro-F1 0.9342 | Train Macro-F1 0.9330 | Val Micro-F1 0.9025 | Val Macro-F1 0.9043\n",
      "------------------\n",
      "The current validation loss: 0.31685709953308105\n",
      "trigger times: 0\n",
      "Epoch 20 | Train Loss 0.2029 | Train Micro-F1 0.9379 | Train Macro-F1 0.9375 | Val Micro-F1 0.9012 | Val Macro-F1 0.9042\n",
      "------------------\n",
      "The current validation loss: 0.2993192970752716\n",
      "trigger times: 0\n",
      "Epoch 21 | Train Loss 0.1861 | Train Micro-F1 0.9454 | Train Macro-F1 0.9458 | Val Micro-F1 0.9075 | Val Macro-F1 0.9106\n",
      "------------------\n",
      "The current validation loss: 0.29391294717788696\n",
      "trigger times: 0\n",
      "Epoch 22 | Train Loss 0.1664 | Train Micro-F1 0.9500 | Train Macro-F1 0.9507 | Val Micro-F1 0.9100 | Val Macro-F1 0.9132\n",
      "------------------\n",
      "The current validation loss: 0.2788394093513489\n",
      "trigger times: 0\n",
      "Epoch 23 | Train Loss 0.1517 | Train Micro-F1 0.9521 | Train Macro-F1 0.9522 | Val Micro-F1 0.9113 | Val Macro-F1 0.9142\n",
      "------------------\n",
      "The current validation loss: 0.27064889669418335\n",
      "trigger times: 0\n",
      "Epoch 24 | Train Loss 0.1363 | Train Micro-F1 0.9546 | Train Macro-F1 0.9551 | Val Micro-F1 0.9087 | Val Macro-F1 0.9112\n",
      "------------------\n",
      "The current validation loss: 0.257088303565979\n",
      "trigger times: 0\n",
      "Epoch 25 | Train Loss 0.1217 | Train Micro-F1 0.9625 | Train Macro-F1 0.9627 | Val Micro-F1 0.9150 | Val Macro-F1 0.9166\n",
      "------------------\n",
      "The current validation loss: 0.2594000995159149\n",
      "trigger times: 1\n",
      "Epoch 26 | Train Loss 0.1153 | Train Micro-F1 0.9621 | Train Macro-F1 0.9624 | Val Micro-F1 0.9150 | Val Macro-F1 0.9164\n",
      "------------------\n",
      "The current validation loss: 0.2709137499332428\n",
      "trigger times: 2\n",
      "Epoch 27 | Train Loss 0.1069 | Train Micro-F1 0.9637 | Train Macro-F1 0.9640 | Val Micro-F1 0.9150 | Val Macro-F1 0.9166\n",
      "------------------\n",
      "The current validation loss: 0.245938241481781\n",
      "trigger times: 0\n",
      "Epoch 28 | Train Loss 0.0977 | Train Micro-F1 0.9675 | Train Macro-F1 0.9676 | Val Micro-F1 0.9163 | Val Macro-F1 0.9183\n",
      "------------------\n",
      "The current validation loss: 0.24027587473392487\n",
      "trigger times: 0\n",
      "Epoch 29 | Train Loss 0.0911 | Train Micro-F1 0.9733 | Train Macro-F1 0.9738 | Val Micro-F1 0.9125 | Val Macro-F1 0.9152\n",
      "------------------\n",
      "The current validation loss: 0.24689653515815735\n",
      "trigger times: 1\n",
      "Epoch 30 | Train Loss 0.0866 | Train Micro-F1 0.9750 | Train Macro-F1 0.9756 | Val Micro-F1 0.9137 | Val Macro-F1 0.9165\n",
      "------------------\n",
      "The current validation loss: 0.2399141490459442\n",
      "trigger times: 0\n",
      "Epoch 31 | Train Loss 0.0807 | Train Micro-F1 0.9742 | Train Macro-F1 0.9747 | Val Micro-F1 0.9175 | Val Macro-F1 0.9200\n",
      "------------------\n",
      "The current validation loss: 0.2483920156955719\n",
      "trigger times: 1\n",
      "Epoch 32 | Train Loss 0.0779 | Train Micro-F1 0.9758 | Train Macro-F1 0.9761 | Val Micro-F1 0.9213 | Val Macro-F1 0.9233\n",
      "------------------\n",
      "The current validation loss: 0.2506009042263031\n",
      "trigger times: 2\n",
      "Epoch 33 | Train Loss 0.0702 | Train Micro-F1 0.9804 | Train Macro-F1 0.9806 | Val Micro-F1 0.9213 | Val Macro-F1 0.9231\n",
      "------------------\n",
      "The current validation loss: 0.24184341728687286\n",
      "trigger times: 3\n",
      "Epoch 34 | Train Loss 0.0662 | Train Micro-F1 0.9825 | Train Macro-F1 0.9828 | Val Micro-F1 0.9187 | Val Macro-F1 0.9204\n",
      "------------------\n",
      "The current validation loss: 0.24073098599910736\n",
      "trigger times: 4\n",
      "Epoch 35 | Train Loss 0.0608 | Train Micro-F1 0.9829 | Train Macro-F1 0.9832 | Val Micro-F1 0.9175 | Val Macro-F1 0.9191\n",
      "------------------\n",
      "The current validation loss: 0.2400733381509781\n",
      "trigger times: 5\n",
      "Epoch 36 | Train Loss 0.0547 | Train Micro-F1 0.9867 | Train Macro-F1 0.9869 | Val Micro-F1 0.9225 | Val Macro-F1 0.9243\n",
      "------------------\n",
      "The current validation loss: 0.23565635085105896\n",
      "trigger times: 0\n",
      "Epoch 37 | Train Loss 0.0496 | Train Micro-F1 0.9883 | Train Macro-F1 0.9885 | Val Micro-F1 0.9250 | Val Macro-F1 0.9269\n",
      "------------------\n",
      "The current validation loss: 0.24008622765541077\n",
      "trigger times: 1\n",
      "Epoch 38 | Train Loss 0.0443 | Train Micro-F1 0.9871 | Train Macro-F1 0.9874 | Val Micro-F1 0.9275 | Val Macro-F1 0.9296\n",
      "------------------\n",
      "The current validation loss: 0.23367838561534882\n",
      "trigger times: 0\n",
      "Epoch 39 | Train Loss 0.0412 | Train Micro-F1 0.9896 | Train Macro-F1 0.9898 | Val Micro-F1 0.9263 | Val Macro-F1 0.9283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "The current validation loss: 0.231105238199234\n",
      "trigger times: 0\n",
      "Epoch 40 | Train Loss 0.0362 | Train Micro-F1 0.9917 | Train Macro-F1 0.9918 | Val Micro-F1 0.9250 | Val Macro-F1 0.9265\n",
      "------------------\n",
      "The current validation loss: 0.23936855792999268\n",
      "trigger times: 1\n",
      "Epoch 41 | Train Loss 0.0299 | Train Micro-F1 0.9921 | Train Macro-F1 0.9922 | Val Micro-F1 0.9313 | Val Macro-F1 0.9325\n",
      "------------------\n",
      "The current validation loss: 0.25296589732170105\n",
      "trigger times: 2\n",
      "Epoch 42 | Train Loss 0.0277 | Train Micro-F1 0.9921 | Train Macro-F1 0.9922 | Val Micro-F1 0.9325 | Val Macro-F1 0.9337\n",
      "------------------\n",
      "The current validation loss: 0.253757119178772\n",
      "trigger times: 3\n",
      "Epoch 43 | Train Loss 0.0237 | Train Micro-F1 0.9938 | Train Macro-F1 0.9938 | Val Micro-F1 0.9300 | Val Macro-F1 0.9315\n",
      "------------------\n",
      "The current validation loss: 0.26428496837615967\n",
      "trigger times: 4\n",
      "Epoch 44 | Train Loss 0.0201 | Train Micro-F1 0.9958 | Train Macro-F1 0.9959 | Val Micro-F1 0.9275 | Val Macro-F1 0.9293\n",
      "------------------\n",
      "The current validation loss: 0.2722034454345703\n",
      "trigger times: 5\n",
      "Epoch 45 | Train Loss 0.0175 | Train Micro-F1 0.9962 | Train Macro-F1 0.9963 | Val Micro-F1 0.9187 | Val Macro-F1 0.9213\n",
      "------------------\n",
      "The current validation loss: 0.2790997326374054\n",
      "trigger times: 6\n",
      "Epoch 46 | Train Loss 0.0151 | Train Micro-F1 0.9967 | Train Macro-F1 0.9968 | Val Micro-F1 0.9175 | Val Macro-F1 0.9202\n",
      "------------------\n",
      "The current validation loss: 0.2871960401535034\n",
      "trigger times: 7\n",
      "Epoch 47 | Train Loss 0.0137 | Train Micro-F1 0.9971 | Train Macro-F1 0.9972 | Val Micro-F1 0.9213 | Val Macro-F1 0.9236\n",
      "------------------\n",
      "The current validation loss: 0.2915634512901306\n",
      "trigger times: 8\n",
      "Epoch 48 | Train Loss 0.0120 | Train Micro-F1 0.9971 | Train Macro-F1 0.9972 | Val Micro-F1 0.9225 | Val Macro-F1 0.9238\n",
      "------------------\n",
      "The current validation loss: 0.3007620573043823\n",
      "trigger times: 9\n",
      "Epoch 49 | Train Loss 0.0101 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.9225 | Val Macro-F1 0.9234\n",
      "------------------\n",
      "The current validation loss: 0.31335198879241943\n",
      "trigger times: 10\n",
      "Epoch 50 | Train Loss 0.0106 | Train Micro-F1 0.9958 | Train Macro-F1 0.9959 | Val Micro-F1 0.9200 | Val Macro-F1 0.9211\n",
      "------------------\n",
      "The current validation loss: 0.3234308958053589\n",
      "trigger times: 11\n",
      "Epoch 51 | Train Loss 0.0093 | Train Micro-F1 0.9971 | Train Macro-F1 0.9972 | Val Micro-F1 0.9187 | Val Macro-F1 0.9205\n",
      "------------------\n",
      "The current validation loss: 0.34236249327659607\n",
      "trigger times: 12\n",
      "Epoch 52 | Train Loss 0.0076 | Train Micro-F1 0.9992 | Train Macro-F1 0.9992 | Val Micro-F1 0.9150 | Val Macro-F1 0.9177\n",
      "------------------\n",
      "The current validation loss: 0.363419771194458\n",
      "trigger times: 13\n",
      "Epoch 53 | Train Loss 0.0065 | Train Micro-F1 0.9996 | Train Macro-F1 0.9996 | Val Micro-F1 0.9150 | Val Macro-F1 0.9181\n",
      "------------------\n",
      "The current validation loss: 0.3727446496486664\n",
      "trigger times: 14\n",
      "Epoch 54 | Train Loss 0.0058 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.9150 | Val Macro-F1 0.9181\n",
      "------------------\n",
      "The current validation loss: 0.37789395451545715\n",
      "trigger times: 15\n",
      "Epoch 55 | Train Loss 0.0052 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.9137 | Val Macro-F1 0.9169\n",
      "------------------\n",
      "The current validation loss: 0.38703280687332153\n",
      "trigger times: 16\n",
      "Epoch 56 | Train Loss 0.0046 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.9087 | Val Macro-F1 0.9118\n",
      "------------------\n",
      "The current validation loss: 0.3967132866382599\n",
      "trigger times: 17\n",
      "Epoch 57 | Train Loss 0.0041 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.9062 | Val Macro-F1 0.9092\n",
      "------------------\n",
      "The current validation loss: 0.4114420413970947\n",
      "trigger times: 18\n",
      "Epoch 58 | Train Loss 0.0036 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.9050 | Val Macro-F1 0.9076\n",
      "------------------\n",
      "The current validation loss: 0.4179629385471344\n",
      "trigger times: 19\n",
      "Epoch 59 | Train Loss 0.0041 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.9038 | Val Macro-F1 0.9063\n",
      "------------------\n",
      "The current validation loss: 0.43126457929611206\n",
      "trigger times: 20\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Test Micro-F1 0.9152 | Test Macro-F1 0.9143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-01 15:53:06,986]\u001b[0m Trial 0 finished with value: 0.231105238199234 and parameters: {'n_layer': 4}. Best is trial 0 with value: 0.231105238199234.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "The current validation loss: 1.153307557106018\n",
      "trigger times: 0\n",
      "Epoch 0 | Train Loss 1.1550 | Train Micro-F1 0.3871 | Train Macro-F1 0.2542 | Val Micro-F1 0.4925 | Val Macro-F1 0.2368\n",
      "------------------\n",
      "The current validation loss: 1.0914709568023682\n",
      "trigger times: 0\n",
      "Epoch 1 | Train Loss 1.0493 | Train Micro-F1 0.4925 | Train Macro-F1 0.3026 | Val Micro-F1 0.5363 | Val Macro-F1 0.3692\n",
      "------------------\n",
      "The current validation loss: 1.0503016710281372\n",
      "trigger times: 0\n",
      "Epoch 2 | Train Loss 1.0248 | Train Micro-F1 0.4954 | Train Macro-F1 0.3577 | Val Micro-F1 0.5650 | Val Macro-F1 0.4024\n",
      "------------------\n",
      "The current validation loss: 1.008346438407898\n",
      "trigger times: 0\n",
      "Epoch 3 | Train Loss 0.9853 | Train Micro-F1 0.5229 | Train Macro-F1 0.4073 | Val Micro-F1 0.5513 | Val Macro-F1 0.3868\n",
      "------------------\n",
      "The current validation loss: 0.9153960347175598\n",
      "trigger times: 0\n",
      "Epoch 4 | Train Loss 0.9155 | Train Micro-F1 0.5837 | Train Macro-F1 0.4866 | Val Micro-F1 0.5600 | Val Macro-F1 0.3981\n",
      "------------------\n",
      "The current validation loss: 0.8964012265205383\n",
      "trigger times: 0\n",
      "Epoch 5 | Train Loss 0.8677 | Train Micro-F1 0.5925 | Train Macro-F1 0.4639 | Val Micro-F1 0.6438 | Val Macro-F1 0.5349\n",
      "------------------\n",
      "The current validation loss: 0.8861887454986572\n",
      "trigger times: 0\n",
      "Epoch 6 | Train Loss 0.8297 | Train Micro-F1 0.6538 | Train Macro-F1 0.5683 | Val Micro-F1 0.7075 | Val Macro-F1 0.6379\n",
      "------------------\n",
      "The current validation loss: 0.8390216827392578\n",
      "trigger times: 0\n",
      "Epoch 7 | Train Loss 0.7710 | Train Micro-F1 0.6937 | Train Macro-F1 0.6228 | Val Micro-F1 0.7863 | Val Macro-F1 0.7659\n",
      "------------------\n",
      "The current validation loss: 0.787555992603302\n",
      "trigger times: 0\n",
      "Epoch 8 | Train Loss 0.7272 | Train Micro-F1 0.7450 | Train Macro-F1 0.7123 | Val Micro-F1 0.8225 | Val Macro-F1 0.8148\n",
      "------------------\n",
      "The current validation loss: 0.7240671515464783\n",
      "trigger times: 0\n",
      "Epoch 9 | Train Loss 0.6636 | Train Micro-F1 0.7908 | Train Macro-F1 0.7694 | Val Micro-F1 0.8200 | Val Macro-F1 0.8096\n",
      "------------------\n",
      "The current validation loss: 0.7144442796707153\n",
      "trigger times: 0\n",
      "Epoch 10 | Train Loss 0.6367 | Train Micro-F1 0.7987 | Train Macro-F1 0.7793 | Val Micro-F1 0.8237 | Val Macro-F1 0.8133\n",
      "------------------\n",
      "The current validation loss: 0.6404994130134583\n",
      "trigger times: 0\n",
      "Epoch 11 | Train Loss 0.5605 | Train Micro-F1 0.8263 | Train Macro-F1 0.8078 | Val Micro-F1 0.8350 | Val Macro-F1 0.8282\n",
      "------------------\n",
      "The current validation loss: 0.5934404134750366\n",
      "trigger times: 0\n",
      "Epoch 12 | Train Loss 0.5044 | Train Micro-F1 0.8467 | Train Macro-F1 0.8351 | Val Micro-F1 0.8600 | Val Macro-F1 0.8589\n",
      "------------------\n",
      "The current validation loss: 0.5566128492355347\n",
      "trigger times: 0\n",
      "Epoch 13 | Train Loss 0.4628 | Train Micro-F1 0.8738 | Train Macro-F1 0.8683 | Val Micro-F1 0.8738 | Val Macro-F1 0.8740\n",
      "------------------\n",
      "The current validation loss: 0.523342490196228\n",
      "trigger times: 0\n",
      "Epoch 14 | Train Loss 0.4373 | Train Micro-F1 0.8933 | Train Macro-F1 0.8873 | Val Micro-F1 0.8875 | Val Macro-F1 0.8881\n",
      "------------------\n",
      "The current validation loss: 0.46535181999206543\n",
      "trigger times: 0\n",
      "Epoch 15 | Train Loss 0.3777 | Train Micro-F1 0.9100 | Train Macro-F1 0.9060 | Val Micro-F1 0.8862 | Val Macro-F1 0.8868\n",
      "------------------\n",
      "The current validation loss: 0.43908435106277466\n",
      "trigger times: 0\n",
      "Epoch 16 | Train Loss 0.3373 | Train Micro-F1 0.9125 | Train Macro-F1 0.9072 | Val Micro-F1 0.8912 | Val Macro-F1 0.8925\n",
      "------------------\n",
      "The current validation loss: 0.3962189853191376\n",
      "trigger times: 0\n",
      "Epoch 17 | Train Loss 0.2937 | Train Micro-F1 0.9242 | Train Macro-F1 0.9223 | Val Micro-F1 0.8950 | Val Macro-F1 0.8963\n",
      "------------------\n",
      "The current validation loss: 0.3874978721141815\n",
      "trigger times: 0\n",
      "Epoch 18 | Train Loss 0.2631 | Train Micro-F1 0.9333 | Train Macro-F1 0.9311 | Val Micro-F1 0.8988 | Val Macro-F1 0.9007\n",
      "------------------\n",
      "The current validation loss: 0.34181877970695496\n",
      "trigger times: 0\n",
      "Epoch 19 | Train Loss 0.2350 | Train Micro-F1 0.9367 | Train Macro-F1 0.9357 | Val Micro-F1 0.9038 | Val Macro-F1 0.9059\n",
      "------------------\n",
      "The current validation loss: 0.33482638001441956\n",
      "trigger times: 0\n",
      "Epoch 20 | Train Loss 0.2064 | Train Micro-F1 0.9367 | Train Macro-F1 0.9348 | Val Micro-F1 0.9062 | Val Macro-F1 0.9093\n",
      "------------------\n",
      "The current validation loss: 0.30272963643074036\n",
      "trigger times: 0\n",
      "Epoch 21 | Train Loss 0.1839 | Train Micro-F1 0.9446 | Train Macro-F1 0.9448 | Val Micro-F1 0.8988 | Val Macro-F1 0.9028\n",
      "------------------\n",
      "The current validation loss: 0.28380241990089417\n",
      "trigger times: 0\n",
      "Epoch 22 | Train Loss 0.1582 | Train Micro-F1 0.9533 | Train Macro-F1 0.9528 | Val Micro-F1 0.8988 | Val Macro-F1 0.9030\n",
      "------------------\n",
      "The current validation loss: 0.27684345841407776\n",
      "trigger times: 0\n",
      "Epoch 23 | Train Loss 0.1462 | Train Micro-F1 0.9542 | Train Macro-F1 0.9545 | Val Micro-F1 0.9075 | Val Macro-F1 0.9105\n",
      "------------------\n",
      "The current validation loss: 0.26982200145721436\n",
      "trigger times: 0\n",
      "Epoch 24 | Train Loss 0.1274 | Train Micro-F1 0.9600 | Train Macro-F1 0.9601 | Val Micro-F1 0.9187 | Val Macro-F1 0.9203\n",
      "------------------\n",
      "The current validation loss: 0.2557816505432129\n",
      "trigger times: 0\n",
      "Epoch 25 | Train Loss 0.1145 | Train Micro-F1 0.9629 | Train Macro-F1 0.9629 | Val Micro-F1 0.9125 | Val Macro-F1 0.9135\n",
      "------------------\n",
      "The current validation loss: 0.2573433220386505\n",
      "trigger times: 1\n",
      "Epoch 26 | Train Loss 0.1082 | Train Micro-F1 0.9650 | Train Macro-F1 0.9653 | Val Micro-F1 0.9113 | Val Macro-F1 0.9125\n",
      "------------------\n",
      "The current validation loss: 0.2485904097557068\n",
      "trigger times: 0\n",
      "Epoch 27 | Train Loss 0.1020 | Train Micro-F1 0.9667 | Train Macro-F1 0.9669 | Val Micro-F1 0.9137 | Val Macro-F1 0.9158\n",
      "------------------\n",
      "The current validation loss: 0.2632688581943512\n",
      "trigger times: 1\n",
      "Epoch 28 | Train Loss 0.0954 | Train Micro-F1 0.9696 | Train Macro-F1 0.9698 | Val Micro-F1 0.9025 | Val Macro-F1 0.9060\n",
      "------------------\n",
      "The current validation loss: 0.25894877314567566\n",
      "trigger times: 2\n",
      "Epoch 29 | Train Loss 0.0888 | Train Micro-F1 0.9729 | Train Macro-F1 0.9735 | Val Micro-F1 0.9025 | Val Macro-F1 0.9063\n",
      "------------------\n",
      "The current validation loss: 0.26279425621032715\n",
      "trigger times: 3\n",
      "Epoch 30 | Train Loss 0.0848 | Train Micro-F1 0.9754 | Train Macro-F1 0.9760 | Val Micro-F1 0.9087 | Val Macro-F1 0.9123\n",
      "------------------\n",
      "The current validation loss: 0.2462940365076065\n",
      "trigger times: 0\n",
      "Epoch 31 | Train Loss 0.0766 | Train Micro-F1 0.9792 | Train Macro-F1 0.9796 | Val Micro-F1 0.9150 | Val Macro-F1 0.9172\n",
      "------------------\n",
      "The current validation loss: 0.23357123136520386\n",
      "trigger times: 0\n",
      "Epoch 32 | Train Loss 0.0689 | Train Micro-F1 0.9821 | Train Macro-F1 0.9824 | Val Micro-F1 0.9150 | Val Macro-F1 0.9164\n",
      "------------------\n",
      "The current validation loss: 0.2442612648010254\n",
      "trigger times: 1\n",
      "Epoch 33 | Train Loss 0.0707 | Train Micro-F1 0.9804 | Train Macro-F1 0.9806 | Val Micro-F1 0.9163 | Val Macro-F1 0.9174\n",
      "------------------\n",
      "The current validation loss: 0.23407785594463348\n",
      "trigger times: 2\n",
      "Epoch 34 | Train Loss 0.0671 | Train Micro-F1 0.9833 | Train Macro-F1 0.9835 | Val Micro-F1 0.9137 | Val Macro-F1 0.9161\n",
      "------------------\n",
      "The current validation loss: 0.23116211593151093\n",
      "trigger times: 0\n",
      "Epoch 35 | Train Loss 0.0544 | Train Micro-F1 0.9850 | Train Macro-F1 0.9853 | Val Micro-F1 0.9187 | Val Macro-F1 0.9225\n",
      "------------------\n",
      "The current validation loss: 0.24529895186424255\n",
      "trigger times: 1\n",
      "Epoch 36 | Train Loss 0.0537 | Train Micro-F1 0.9846 | Train Macro-F1 0.9849 | Val Micro-F1 0.9125 | Val Macro-F1 0.9162\n",
      "------------------\n",
      "The current validation loss: 0.24522925913333893\n",
      "trigger times: 2\n",
      "Epoch 37 | Train Loss 0.0511 | Train Micro-F1 0.9867 | Train Macro-F1 0.9870 | Val Micro-F1 0.9137 | Val Macro-F1 0.9160\n",
      "------------------\n",
      "The current validation loss: 0.24727460741996765\n",
      "trigger times: 3\n",
      "Epoch 38 | Train Loss 0.0413 | Train Micro-F1 0.9896 | Train Macro-F1 0.9898 | Val Micro-F1 0.9125 | Val Macro-F1 0.9143\n",
      "------------------\n",
      "The current validation loss: 0.24093471467494965\n",
      "trigger times: 4\n",
      "Epoch 39 | Train Loss 0.0349 | Train Micro-F1 0.9925 | Train Macro-F1 0.9926 | Val Micro-F1 0.9125 | Val Macro-F1 0.9131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "The current validation loss: 0.24812360107898712\n",
      "trigger times: 5\n",
      "Epoch 40 | Train Loss 0.0312 | Train Micro-F1 0.9929 | Train Macro-F1 0.9931 | Val Micro-F1 0.9125 | Val Macro-F1 0.9126\n",
      "------------------\n",
      "The current validation loss: 0.25872981548309326\n",
      "trigger times: 6\n",
      "Epoch 41 | Train Loss 0.0305 | Train Micro-F1 0.9917 | Train Macro-F1 0.9918 | Val Micro-F1 0.9125 | Val Macro-F1 0.9128\n",
      "------------------\n",
      "The current validation loss: 0.26667433977127075\n",
      "trigger times: 7\n",
      "Epoch 42 | Train Loss 0.0257 | Train Micro-F1 0.9938 | Train Macro-F1 0.9939 | Val Micro-F1 0.9175 | Val Macro-F1 0.9187\n",
      "------------------\n",
      "The current validation loss: 0.2741127610206604\n",
      "trigger times: 8\n",
      "Epoch 43 | Train Loss 0.0201 | Train Micro-F1 0.9962 | Train Macro-F1 0.9963 | Val Micro-F1 0.9150 | Val Macro-F1 0.9168\n",
      "------------------\n",
      "The current validation loss: 0.27823805809020996\n",
      "trigger times: 9\n",
      "Epoch 44 | Train Loss 0.0187 | Train Micro-F1 0.9962 | Train Macro-F1 0.9963 | Val Micro-F1 0.9137 | Val Macro-F1 0.9159\n",
      "------------------\n",
      "The current validation loss: 0.29649460315704346\n",
      "trigger times: 10\n",
      "Epoch 45 | Train Loss 0.0181 | Train Micro-F1 0.9958 | Train Macro-F1 0.9960 | Val Micro-F1 0.9125 | Val Macro-F1 0.9148\n",
      "------------------\n",
      "The current validation loss: 0.2973926067352295\n",
      "trigger times: 11\n",
      "Epoch 46 | Train Loss 0.0160 | Train Micro-F1 0.9971 | Train Macro-F1 0.9972 | Val Micro-F1 0.9150 | Val Macro-F1 0.9168\n",
      "------------------\n",
      "The current validation loss: 0.2908138036727905\n",
      "trigger times: 12\n",
      "Epoch 47 | Train Loss 0.0118 | Train Micro-F1 0.9983 | Train Macro-F1 0.9984 | Val Micro-F1 0.9187 | Val Macro-F1 0.9202\n",
      "------------------\n",
      "The current validation loss: 0.3039306402206421\n",
      "trigger times: 13\n",
      "Epoch 48 | Train Loss 0.0101 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.9187 | Val Macro-F1 0.9199\n",
      "------------------\n",
      "The current validation loss: 0.3040544390678406\n",
      "trigger times: 14\n",
      "Epoch 49 | Train Loss 0.0100 | Train Micro-F1 0.9971 | Train Macro-F1 0.9972 | Val Micro-F1 0.9163 | Val Macro-F1 0.9173\n",
      "------------------\n",
      "The current validation loss: 0.31755974888801575\n",
      "trigger times: 15\n",
      "Epoch 50 | Train Loss 0.0086 | Train Micro-F1 0.9983 | Train Macro-F1 0.9984 | Val Micro-F1 0.9163 | Val Macro-F1 0.9173\n",
      "------------------\n",
      "The current validation loss: 0.3295994699001312\n",
      "trigger times: 16\n",
      "Epoch 51 | Train Loss 0.0090 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.9163 | Val Macro-F1 0.9176\n",
      "------------------\n",
      "The current validation loss: 0.3386775553226471\n",
      "trigger times: 17\n",
      "Epoch 52 | Train Loss 0.0064 | Train Micro-F1 0.9992 | Train Macro-F1 0.9992 | Val Micro-F1 0.9113 | Val Macro-F1 0.9137\n",
      "------------------\n",
      "The current validation loss: 0.3527929186820984\n",
      "trigger times: 18\n",
      "Epoch 53 | Train Loss 0.0052 | Train Micro-F1 0.9996 | Train Macro-F1 0.9996 | Val Micro-F1 0.9087 | Val Macro-F1 0.9118\n",
      "------------------\n",
      "The current validation loss: 0.3967683017253876\n",
      "trigger times: 19\n",
      "Epoch 54 | Train Loss 0.0051 | Train Micro-F1 0.9996 | Train Macro-F1 0.9996 | Val Micro-F1 0.9087 | Val Macro-F1 0.9119\n",
      "------------------\n",
      "The current validation loss: 0.4110722839832306\n",
      "trigger times: 20\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Test Micro-F1 0.9079 | Test Macro-F1 0.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-01 15:55:17,267]\u001b[0m Trial 1 finished with value: 0.23116211593151093 and parameters: {'n_layer': 2}. Best is trial 0 with value: 0.231105238199234.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "The current validation loss: 1.1567796468734741\n",
      "trigger times: 0\n",
      "Epoch 0 | Train Loss 1.1530 | Train Micro-F1 0.3396 | Train Macro-F1 0.3302 | Val Micro-F1 0.4875 | Val Macro-F1 0.2185\n",
      "------------------\n",
      "The current validation loss: 1.0912895202636719\n",
      "trigger times: 0\n",
      "Epoch 1 | Train Loss 1.0662 | Train Micro-F1 0.5021 | Train Macro-F1 0.2755 | Val Micro-F1 0.4875 | Val Macro-F1 0.2185\n",
      "------------------\n",
      "The current validation loss: 1.0596485137939453\n",
      "trigger times: 0\n",
      "Epoch 2 | Train Loss 1.0125 | Train Micro-F1 0.4996 | Train Macro-F1 0.2733 | Val Micro-F1 0.4975 | Val Macro-F1 0.2602\n",
      "------------------\n",
      "The current validation loss: 0.9617285132408142\n",
      "trigger times: 0\n",
      "Epoch 3 | Train Loss 0.9467 | Train Micro-F1 0.5404 | Train Macro-F1 0.4175 | Val Micro-F1 0.6725 | Val Macro-F1 0.6356\n",
      "------------------\n",
      "The current validation loss: 0.9361514449119568\n",
      "trigger times: 0\n",
      "Epoch 4 | Train Loss 0.9009 | Train Micro-F1 0.5950 | Train Macro-F1 0.5514 | Val Micro-F1 0.7475 | Val Macro-F1 0.7398\n",
      "------------------\n",
      "The current validation loss: 0.8862652778625488\n",
      "trigger times: 0\n",
      "Epoch 5 | Train Loss 0.8511 | Train Micro-F1 0.6488 | Train Macro-F1 0.6325 | Val Micro-F1 0.7700 | Val Macro-F1 0.7578\n",
      "------------------\n",
      "The current validation loss: 0.8305537700653076\n",
      "trigger times: 0\n",
      "Epoch 6 | Train Loss 0.7761 | Train Micro-F1 0.7121 | Train Macro-F1 0.6975 | Val Micro-F1 0.7400 | Val Macro-F1 0.7040\n",
      "------------------\n",
      "The current validation loss: 0.8192262053489685\n",
      "trigger times: 0\n",
      "Epoch 7 | Train Loss 0.7675 | Train Micro-F1 0.7200 | Train Macro-F1 0.6952 | Val Micro-F1 0.6613 | Val Macro-F1 0.5770\n",
      "------------------\n",
      "The current validation loss: 0.7581170797348022\n",
      "trigger times: 0\n",
      "Epoch 8 | Train Loss 0.6889 | Train Micro-F1 0.6958 | Train Macro-F1 0.6343 | Val Micro-F1 0.6763 | Val Macro-F1 0.6052\n",
      "------------------\n",
      "The current validation loss: 0.6829330921173096\n",
      "trigger times: 0\n",
      "Epoch 9 | Train Loss 0.6312 | Train Micro-F1 0.7513 | Train Macro-F1 0.7133 | Val Micro-F1 0.7425 | Val Macro-F1 0.7123\n",
      "------------------\n",
      "The current validation loss: 0.6935665011405945\n",
      "trigger times: 1\n",
      "Epoch 10 | Train Loss 0.6159 | Train Micro-F1 0.7492 | Train Macro-F1 0.7167 | Val Micro-F1 0.8075 | Val Macro-F1 0.8010\n",
      "------------------\n",
      "The current validation loss: 0.6041668653488159\n",
      "trigger times: 0\n",
      "Epoch 11 | Train Loss 0.5380 | Train Micro-F1 0.8100 | Train Macro-F1 0.7950 | Val Micro-F1 0.8600 | Val Macro-F1 0.8617\n",
      "------------------\n",
      "The current validation loss: 0.5588690042495728\n",
      "trigger times: 0\n",
      "Epoch 12 | Train Loss 0.4809 | Train Micro-F1 0.8771 | Train Macro-F1 0.8753 | Val Micro-F1 0.8750 | Val Macro-F1 0.8799\n",
      "------------------\n",
      "The current validation loss: 0.5477534532546997\n",
      "trigger times: 0\n",
      "Epoch 13 | Train Loss 0.4592 | Train Micro-F1 0.8854 | Train Macro-F1 0.8871 | Val Micro-F1 0.8850 | Val Macro-F1 0.8895\n",
      "------------------\n",
      "The current validation loss: 0.527185320854187\n",
      "trigger times: 0\n",
      "Epoch 14 | Train Loss 0.4357 | Train Micro-F1 0.8921 | Train Macro-F1 0.8919 | Val Micro-F1 0.8862 | Val Macro-F1 0.8890\n",
      "------------------\n",
      "The current validation loss: 0.48708897829055786\n",
      "trigger times: 0\n",
      "Epoch 15 | Train Loss 0.3889 | Train Micro-F1 0.9025 | Train Macro-F1 0.9025 | Val Micro-F1 0.8825 | Val Macro-F1 0.8841\n",
      "------------------\n",
      "The current validation loss: 0.43963566422462463\n",
      "trigger times: 0\n",
      "Epoch 16 | Train Loss 0.3448 | Train Micro-F1 0.9079 | Train Macro-F1 0.9071 | Val Micro-F1 0.8762 | Val Macro-F1 0.8762\n",
      "------------------\n",
      "The current validation loss: 0.40221458673477173\n",
      "trigger times: 0\n",
      "Epoch 17 | Train Loss 0.2973 | Train Micro-F1 0.9133 | Train Macro-F1 0.9119 | Val Micro-F1 0.8762 | Val Macro-F1 0.8766\n",
      "------------------\n",
      "The current validation loss: 0.3994995355606079\n",
      "trigger times: 0\n",
      "Epoch 18 | Train Loss 0.2818 | Train Micro-F1 0.9096 | Train Macro-F1 0.9072 | Val Micro-F1 0.8775 | Val Macro-F1 0.8783\n",
      "------------------\n",
      "The current validation loss: 0.3613334000110626\n",
      "trigger times: 0\n",
      "Epoch 19 | Train Loss 0.2461 | Train Micro-F1 0.9213 | Train Macro-F1 0.9197 | Val Micro-F1 0.8938 | Val Macro-F1 0.8956\n",
      "------------------\n",
      "The current validation loss: 0.33396488428115845\n",
      "trigger times: 0\n",
      "Epoch 20 | Train Loss 0.2170 | Train Micro-F1 0.9296 | Train Macro-F1 0.9286 | Val Micro-F1 0.8950 | Val Macro-F1 0.8982\n",
      "------------------\n",
      "The current validation loss: 0.32754436135292053\n",
      "trigger times: 0\n",
      "Epoch 21 | Train Loss 0.2028 | Train Micro-F1 0.9433 | Train Macro-F1 0.9436 | Val Micro-F1 0.8975 | Val Macro-F1 0.9015\n",
      "------------------\n",
      "The current validation loss: 0.2889347970485687\n",
      "trigger times: 0\n",
      "Epoch 22 | Train Loss 0.1789 | Train Micro-F1 0.9433 | Train Macro-F1 0.9438 | Val Micro-F1 0.9012 | Val Macro-F1 0.9052\n",
      "------------------\n",
      "The current validation loss: 0.30392807722091675\n",
      "trigger times: 1\n",
      "Epoch 23 | Train Loss 0.1700 | Train Micro-F1 0.9492 | Train Macro-F1 0.9503 | Val Micro-F1 0.9075 | Val Macro-F1 0.9099\n",
      "------------------\n",
      "The current validation loss: 0.2957693934440613\n",
      "trigger times: 2\n",
      "Epoch 24 | Train Loss 0.1519 | Train Micro-F1 0.9521 | Train Macro-F1 0.9524 | Val Micro-F1 0.9062 | Val Macro-F1 0.9081\n",
      "------------------\n",
      "The current validation loss: 0.2789445221424103\n",
      "trigger times: 0\n",
      "Epoch 25 | Train Loss 0.1381 | Train Micro-F1 0.9492 | Train Macro-F1 0.9488 | Val Micro-F1 0.9000 | Val Macro-F1 0.9015\n",
      "------------------\n",
      "The current validation loss: 0.2683754861354828\n",
      "trigger times: 0\n",
      "Epoch 26 | Train Loss 0.1276 | Train Micro-F1 0.9583 | Train Macro-F1 0.9584 | Val Micro-F1 0.9025 | Val Macro-F1 0.9046\n",
      "------------------\n",
      "The current validation loss: 0.26423180103302\n",
      "trigger times: 0\n",
      "Epoch 27 | Train Loss 0.1157 | Train Micro-F1 0.9613 | Train Macro-F1 0.9616 | Val Micro-F1 0.9087 | Val Macro-F1 0.9112\n",
      "------------------\n",
      "The current validation loss: 0.25106751918792725\n",
      "trigger times: 0\n",
      "Epoch 28 | Train Loss 0.1022 | Train Micro-F1 0.9654 | Train Macro-F1 0.9657 | Val Micro-F1 0.9137 | Val Macro-F1 0.9166\n",
      "------------------\n",
      "The current validation loss: 0.24329246580600739\n",
      "trigger times: 0\n",
      "Epoch 29 | Train Loss 0.0968 | Train Micro-F1 0.9646 | Train Macro-F1 0.9650 | Val Micro-F1 0.9100 | Val Macro-F1 0.9135\n",
      "------------------\n",
      "The current validation loss: 0.24325861036777496\n",
      "trigger times: 0\n",
      "Epoch 30 | Train Loss 0.0899 | Train Micro-F1 0.9708 | Train Macro-F1 0.9714 | Val Micro-F1 0.9100 | Val Macro-F1 0.9135\n",
      "------------------\n",
      "The current validation loss: 0.24625834822654724\n",
      "trigger times: 1\n",
      "Epoch 31 | Train Loss 0.0861 | Train Micro-F1 0.9733 | Train Macro-F1 0.9738 | Val Micro-F1 0.9100 | Val Macro-F1 0.9136\n",
      "------------------\n",
      "The current validation loss: 0.24405233561992645\n",
      "trigger times: 2\n",
      "Epoch 32 | Train Loss 0.0769 | Train Micro-F1 0.9767 | Train Macro-F1 0.9772 | Val Micro-F1 0.9150 | Val Macro-F1 0.9176\n",
      "------------------\n",
      "The current validation loss: 0.2391563057899475\n",
      "trigger times: 0\n",
      "Epoch 33 | Train Loss 0.0689 | Train Micro-F1 0.9779 | Train Macro-F1 0.9784 | Val Micro-F1 0.9150 | Val Macro-F1 0.9170\n",
      "------------------\n",
      "The current validation loss: 0.24351640045642853\n",
      "trigger times: 1\n",
      "Epoch 34 | Train Loss 0.0620 | Train Micro-F1 0.9821 | Train Macro-F1 0.9824 | Val Micro-F1 0.9125 | Val Macro-F1 0.9143\n",
      "------------------\n",
      "The current validation loss: 0.2364652454853058\n",
      "trigger times: 0\n",
      "Epoch 35 | Train Loss 0.0606 | Train Micro-F1 0.9817 | Train Macro-F1 0.9820 | Val Micro-F1 0.9150 | Val Macro-F1 0.9170\n",
      "------------------\n",
      "The current validation loss: 0.2482316642999649\n",
      "trigger times: 1\n",
      "Epoch 36 | Train Loss 0.0552 | Train Micro-F1 0.9829 | Train Macro-F1 0.9829 | Val Micro-F1 0.9137 | Val Macro-F1 0.9154\n",
      "------------------\n",
      "The current validation loss: 0.24800977110862732\n",
      "trigger times: 2\n",
      "Epoch 37 | Train Loss 0.0533 | Train Micro-F1 0.9825 | Train Macro-F1 0.9828 | Val Micro-F1 0.9125 | Val Macro-F1 0.9143\n",
      "------------------\n",
      "The current validation loss: 0.2513303756713867\n",
      "trigger times: 3\n",
      "Epoch 38 | Train Loss 0.0454 | Train Micro-F1 0.9858 | Train Macro-F1 0.9861 | Val Micro-F1 0.9113 | Val Macro-F1 0.9133\n",
      "------------------\n",
      "The current validation loss: 0.25471583008766174\n",
      "trigger times: 4\n",
      "Epoch 39 | Train Loss 0.0394 | Train Micro-F1 0.9892 | Train Macro-F1 0.9894 | Val Micro-F1 0.9113 | Val Macro-F1 0.9131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "The current validation loss: 0.2505854666233063\n",
      "trigger times: 5\n",
      "Epoch 40 | Train Loss 0.0365 | Train Micro-F1 0.9904 | Train Macro-F1 0.9906 | Val Micro-F1 0.9175 | Val Macro-F1 0.9191\n",
      "------------------\n",
      "The current validation loss: 0.2549072206020355\n",
      "trigger times: 6\n",
      "Epoch 41 | Train Loss 0.0318 | Train Micro-F1 0.9925 | Train Macro-F1 0.9926 | Val Micro-F1 0.9175 | Val Macro-F1 0.9191\n",
      "------------------\n",
      "The current validation loss: 0.24690234661102295\n",
      "trigger times: 7\n",
      "Epoch 42 | Train Loss 0.0277 | Train Micro-F1 0.9946 | Train Macro-F1 0.9947 | Val Micro-F1 0.9175 | Val Macro-F1 0.9192\n",
      "------------------\n",
      "The current validation loss: 0.2422560155391693\n",
      "trigger times: 8\n",
      "Epoch 43 | Train Loss 0.0236 | Train Micro-F1 0.9954 | Train Macro-F1 0.9955 | Val Micro-F1 0.9200 | Val Macro-F1 0.9216\n",
      "------------------\n",
      "The current validation loss: 0.25813353061676025\n",
      "trigger times: 9\n",
      "Epoch 44 | Train Loss 0.0212 | Train Micro-F1 0.9958 | Train Macro-F1 0.9959 | Val Micro-F1 0.9213 | Val Macro-F1 0.9230\n",
      "------------------\n",
      "The current validation loss: 0.25552839040756226\n",
      "trigger times: 10\n",
      "Epoch 45 | Train Loss 0.0184 | Train Micro-F1 0.9967 | Train Macro-F1 0.9968 | Val Micro-F1 0.9187 | Val Macro-F1 0.9209\n",
      "------------------\n",
      "The current validation loss: 0.27428722381591797\n",
      "trigger times: 11\n",
      "Epoch 46 | Train Loss 0.0153 | Train Micro-F1 0.9971 | Train Macro-F1 0.9972 | Val Micro-F1 0.9163 | Val Macro-F1 0.9190\n",
      "------------------\n",
      "The current validation loss: 0.26649168133735657\n",
      "trigger times: 12\n",
      "Epoch 47 | Train Loss 0.0131 | Train Micro-F1 0.9983 | Train Macro-F1 0.9984 | Val Micro-F1 0.9175 | Val Macro-F1 0.9204\n",
      "------------------\n",
      "The current validation loss: 0.2798411250114441\n",
      "trigger times: 13\n",
      "Epoch 48 | Train Loss 0.0117 | Train Micro-F1 0.9979 | Train Macro-F1 0.9980 | Val Micro-F1 0.9137 | Val Macro-F1 0.9166\n",
      "------------------\n",
      "The current validation loss: 0.2868179380893707\n",
      "trigger times: 14\n",
      "Epoch 49 | Train Loss 0.0101 | Train Micro-F1 0.9988 | Train Macro-F1 0.9988 | Val Micro-F1 0.9113 | Val Macro-F1 0.9135\n",
      "------------------\n",
      "The current validation loss: 0.30807456374168396\n",
      "trigger times: 15\n",
      "Epoch 50 | Train Loss 0.0083 | Train Micro-F1 0.9992 | Train Macro-F1 0.9992 | Val Micro-F1 0.9100 | Val Macro-F1 0.9117\n",
      "------------------\n",
      "The current validation loss: 0.3192603588104248\n",
      "trigger times: 16\n",
      "Epoch 51 | Train Loss 0.0069 | Train Micro-F1 0.9992 | Train Macro-F1 0.9992 | Val Micro-F1 0.9113 | Val Macro-F1 0.9121\n",
      "------------------\n",
      "The current validation loss: 0.3360286056995392\n",
      "trigger times: 17\n",
      "Epoch 52 | Train Loss 0.0064 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.9075 | Val Macro-F1 0.9081\n",
      "------------------\n",
      "The current validation loss: 0.3534424304962158\n",
      "trigger times: 18\n",
      "Epoch 53 | Train Loss 0.0068 | Train Micro-F1 0.9996 | Train Macro-F1 0.9996 | Val Micro-F1 0.9075 | Val Macro-F1 0.9083\n",
      "------------------\n",
      "The current validation loss: 0.36715084314346313\n",
      "trigger times: 19\n",
      "Epoch 54 | Train Loss 0.0063 | Train Micro-F1 0.9996 | Train Macro-F1 0.9996 | Val Micro-F1 0.9025 | Val Macro-F1 0.9039\n",
      "------------------\n",
      "The current validation loss: 0.38327866792678833\n",
      "trigger times: 20\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Test Micro-F1 0.9079 | Test Macro-F1 0.9072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-01 15:57:30,401]\u001b[0m Trial 2 finished with value: 0.2364652454853058 and parameters: {'n_layer': 2}. Best is trial 0 with value: 0.231105238199234.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data, g = load_and_process('acm')\n",
    "study = optuna.create_study()  # Create a new study.\n",
    "study.optimize(objective, n_trials=3)  # Invoke optimization of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbfa9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
