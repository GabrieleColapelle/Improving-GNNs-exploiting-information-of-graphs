{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e456a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "import dgl\n",
    "from dgl.nn import HeteroGraphConv\n",
    "from dgl.utils import extract_node_subframes, set_new_frames\n",
    "\n",
    "from sklearn.metrics import f1_score, normalized_mutual_info_score, adjusted_rand_score\n",
    "\n",
    "import copy\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "import json\n",
    "import ast\n",
    "import collections\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e77b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_com_info_DBLP():    \n",
    "    with open('com_dict_LPA_DBLP.txt') as f:\n",
    "        data_dict = f.read()\n",
    "    com_dict = ast.literal_eval(data_dict)\n",
    "    com = []\n",
    "    #find the max community label\n",
    "    val_p = max(com_dict['paper'])\n",
    "    val_a = max(com_dict['author'])\n",
    "    val_c = max(com_dict['conf'])\n",
    "    val_t = max(com_dict['term'])\n",
    "\n",
    "    com.append(val_p)\n",
    "    com.append(val_a)\n",
    "    com.append(val_c)\n",
    "    com.append(val_t)\n",
    "    num_com = max(com) + 1\n",
    "    com_dim_emb = 10\n",
    "    return com_dict,num_com,com_dim_emb\n",
    "\n",
    "def get_com_info_IMDb():    \n",
    "    with open('com_dict_lpa_IMDb.txt') as f:\n",
    "        data_dict = f.read()\n",
    "    com_dict = ast.literal_eval(data_dict)\n",
    "    #find the max community label\n",
    "    com = []\n",
    "    val_a = max(com_dict['actor'])\n",
    "    val_m = max(com_dict['movie'])\n",
    "    val_d = max(com_dict['director'])\n",
    "   \n",
    "    com.append(val_a)\n",
    "    com.append(val_m)\n",
    "    com.append(val_d)\n",
    "    num_com = max(com) + 1\n",
    "    com_dim_emb = 10\n",
    "    return com_dict,num_com,com_dim_emb\n",
    "\n",
    "def get_com_info_ACM():    \n",
    "    with open('com_dict_Lpa_ACM.txt') as f:\n",
    "        data_dict = f.read()\n",
    "    com_dict = ast.literal_eval(data_dict)\n",
    "    #find the max community label\n",
    "    com = []\n",
    "    val_a = max(com_dict['author'])\n",
    "    val_p = max(com_dict['paper'])\n",
    "    val_f = max(com_dict['field'])\n",
    "   \n",
    "    com.append(val_a)\n",
    "    com.append(val_p)\n",
    "    com.append(val_f)\n",
    "    num_com = max(com) + 1\n",
    "    com_dim_emb = 10\n",
    "    return com_dict,num_com,com_dim_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019aa5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_com_LPA_DBLP(hg):\n",
    "    #convert into homogenous graph\n",
    "    g = dgl.to_homogeneous(hg, store_type=True)\n",
    "    nxg = g.to_networkx(node_attrs=['_ID', '_TYPE'], edge_attrs=['_ID', '_TYPE'])\n",
    "    n = nxg.to_undirected()\n",
    "    G2 = nx.Graph(n)\n",
    "    d = community.label_propagation_communities(G2)\n",
    "    #ids: dictionary with key the id of the node and value the type of the node\n",
    "    #mapping of types after networkx conversion\n",
    "    #author -->0 conf -->1 paper -->2 term -->3\n",
    "    ids = nx.get_node_attributes(nxg, \"_TYPE\")\n",
    "    \n",
    "    data = []\n",
    "    #building list cointaining the lists of nodes ids for each community\n",
    "    for i in range(len(d)):\n",
    "        data.append(torch.Tensor(list(list(d)[i])).to(torch.int64))\n",
    "    \n",
    "    papers = {}\n",
    "    authors = {}\n",
    "    terms = {}\n",
    "    conf = {}\n",
    "    \n",
    "    #counter for node ids\n",
    "    a,p,c,t = 0, 0, 0, 0\n",
    "    \n",
    "    #initialize dictionary containing the id of node as key and id of community as value\n",
    "    com_dict = {}\n",
    "    for i in range(len(data)):\n",
    "        for el in data[i]:\n",
    "            com_dict[el.item()] = i\n",
    "            \n",
    "    #order the dictionary by key\n",
    "    ordered_com_dict = collections.OrderedDict(sorted(com_dict.items()))\n",
    "    \n",
    "    #seed dictionary for each node type with node id as value ( given by the counter of node id \n",
    "    #and community as value\n",
    "    for el in ordered_com_dict:\n",
    "        if ids[el] == 0:\n",
    "            authors[a] = ordered_com_dict[el]\n",
    "            a = a + 1\n",
    "        if ids[el] == 1:\n",
    "            conf[c] = ordered_com_dict[el]\n",
    "            c = c + 1\n",
    "        if ids[el] == 2:\n",
    "            papers[p] = ordered_com_dict[el]\n",
    "            p = p + 1\n",
    "        if ids[el] == 3:\n",
    "            terms[t] = ordered_com_dict[el]\n",
    "            t = t + 1\n",
    "\n",
    "    #seed the final dictionary with the node types dictionaries calculated before \n",
    "    dict2 = {}\n",
    "    dict2['paper'] = list(papers.values())\n",
    "    dict2['author'] = list(authors.values())\n",
    "    dict2['conf'] = list(conf.values())\n",
    "    dict2['term'] = list(terms.values())\n",
    "\n",
    "    #write dictionary in txt file\n",
    "    with open('com_dict_LPA_DBLP.txt', 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(dict2))\n",
    "    name = \"com_dict_LPA_DBLP.txt\"\n",
    "    return name\n",
    "        \n",
    "def get_com_LOUVAIN_DBLP(hg):\n",
    "    g = dgl.to_homogeneous(hg, store_type=True)\n",
    "    nxg = g.to_networkx(node_attrs=['_ID', '_TYPE'], edge_attrs=['_ID', '_TYPE'])\n",
    "    n = nxg.to_undirected()\n",
    "    G2 = nx.Graph(n)\n",
    "    d = community.louvain_communities(G2)\n",
    "    ids = nx.get_node_attributes(nxg, \"_TYPE\")\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(d)):\n",
    "        data.append(torch.Tensor(list(list(d)[i])).to(torch.int64))\n",
    "    print(data)\n",
    "\n",
    "    papers = {}\n",
    "    authors = {}\n",
    "    terms = {}\n",
    "    conf = {}\n",
    "    a,p,c,t = 0, 0, 0, 0\n",
    "    \n",
    "    com_dict = {}\n",
    "    for i in range(len(data)):\n",
    "        for el in data[i]:\n",
    "            com_dict[el.item()] = i\n",
    "    ordered_com_dict = collections.OrderedDict(sorted(com_dict.items()))\n",
    "    #list_id = list(dict.keys())\n",
    "\n",
    "    for el in ordered_com_dict:\n",
    "        if ids[el] == 0:\n",
    "            authors[a] = ordered_com_dict[el]\n",
    "            a = a + 1\n",
    "        if ids[el] == 1:\n",
    "            conf[c] = ordered_com_dict[el]\n",
    "            c = c + 1\n",
    "        if ids[el] == 2:\n",
    "            papers[p] = ordered_com_dict[el]\n",
    "            p = p + 1\n",
    "        if ids[el] == 3:\n",
    "            terms[t] = ordered_com_dict[el]\n",
    "            t = t + 1\n",
    "            \n",
    "    dict2 = {}\n",
    "    dict2['paper'] = list(papers.values())\n",
    "    dict2['author'] = list(authors.values())\n",
    "    dict2['conf'] = list(conf.values())\n",
    "    dict2['term'] = list(terms.values())\n",
    "\n",
    "    with open('com_dict_Louvain_DBLP.txt', 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(dict2))\n",
    "    name = 'com_dict_Louvain_DBLP.txt'\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_com_LPA_IMDb(hg):\n",
    "    g = dgl.to_homogeneous(hg, store_type=True)\n",
    "    nxg = g.to_networkx(node_attrs=['_ID', '_TYPE'], edge_attrs=['_ID', '_TYPE'])\n",
    "    n = nxg.to_undirected()\n",
    "    G2 = nx.Graph(n)\n",
    "    d = community.label_propagation_communities(G2)\n",
    "    ids = nx.get_node_attributes(nxg, \"_TYPE\")\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(d)):\n",
    "        data.append(torch.Tensor(list(list(d)[i])).to(torch.int64))\n",
    "    print(data)\n",
    "\n",
    "    print(len(data))\n",
    "    actors = {}\n",
    "    movies = {}\n",
    "    directors = {}\n",
    "\n",
    "    a,m,d = 0, 0, 0\n",
    "    \n",
    "    com_dict = {}\n",
    "    for i in range(len(data)):\n",
    "        for el in data[i]:\n",
    "            com_dict[el.item()] = i\n",
    "    ordered_com_dict = collections.OrderedDict(sorted(com_dict.items()))\n",
    "    #list_id = list(dict.keys())\n",
    "\n",
    "    for el in ordered_com_dict:\n",
    "        #print(el)\n",
    "        if ids[el] == 0:\n",
    "            actors[a] = ordered_com_dict[el]\n",
    "            a = a + 1\n",
    "        if ids[el] == 1:\n",
    "            directors[d] = ordered_com_dict[el]\n",
    "            d = d + 1\n",
    "        if ids[el] == 2:\n",
    "            movies[m] = ordered_com_dict[el]\n",
    "            m = m + 1\n",
    "\n",
    "    dict2 = {}\n",
    "    dict2['actor'] = list(actors.values())\n",
    "    dict2['movie'] = list(movies.values())\n",
    "    dict2['director'] = list(directors.values())\n",
    "\n",
    "    with open('com_dict_LPA_IMDb.txt', 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(dict2))\n",
    "    name = 'com_dict_LPA_IMDbtxt'\n",
    "    return name\n",
    "        \n",
    "def get_com_LOUVAIN_IMDb(hg):\n",
    "    g = dgl.to_homogeneous(hg, store_type=True)\n",
    "    nxg = g.to_networkx(node_attrs=['_ID', '_TYPE'], edge_attrs=['_ID', '_TYPE'])\n",
    "    n = nxg.to_undirected()\n",
    "    G2 = nx.Graph(n)\n",
    "    d = community.louvain_communities(G2)\n",
    "    ids = nx.get_node_attributes(nxg, \"_TYPE\")\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(d)):\n",
    "        data.append(torch.Tensor(list(list(d)[i])).to(torch.int64))\n",
    "    print(data)\n",
    "\n",
    "    print(len(data))\n",
    "    actors = {}\n",
    "    movies = {}\n",
    "    directors = {}\n",
    "\n",
    "    a,m,d = 0, 0, 0\n",
    "    \n",
    "    com_dict = {}\n",
    "    for i in range(len(data)):\n",
    "        for el in data[i]:\n",
    "            com_dict[el.item()] = i\n",
    "    ordered_com_dict = collections.OrderedDict(sorted(com_dict.items()))\n",
    "\n",
    "    for el in ordered_com_dict:\n",
    "        #print(el)\n",
    "        if ids[el] == 0:\n",
    "            actors[a] = ordered_com_dict[el]\n",
    "            a = a + 1\n",
    "        if ids[el] == 1:\n",
    "            directors[d] = ordered_com_dict[el]\n",
    "            d = d + 1\n",
    "        if ids[el] == 2:\n",
    "            movies[m] = ordered_com_dict[el]\n",
    "            m = m + 1\n",
    "    dict2 = {}\n",
    "    \n",
    "    dict2['actor'] = list(actors.values())\n",
    "    dict2['movie'] = list(movies.values())\n",
    "    dict2['director'] = list(directors.values())\n",
    "\n",
    "    with open('com_dict_Louvain_IMDb.txt', 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(dict2))\n",
    "    name = 'com_dict_Louvain_IMDbtxt'\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe921b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_com_LPA_ACM(hg):\n",
    "    g = dgl.to_homogeneous(hg, store_type=True)\n",
    "    nxg = g.to_networkx(node_attrs=['_ID', '_TYPE'], edge_attrs=['_ID', '_TYPE'])\n",
    "    n = nxg.to_undirected()\n",
    "    G2 = nx.Graph(n)\n",
    "    d = community.label_propagation_communities(G2)\n",
    "    ids = nx.get_node_attributes(nxg, \"_TYPE\")\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(d)):\n",
    "        data.append(torch.Tensor(list(list(d)[i])).to(torch.int64))\n",
    "    print(data)\n",
    "\n",
    "    print(len(data))\n",
    "    authors = {}\n",
    "    papers = {}\n",
    "    fields = {}\n",
    "\n",
    "    a,p,f = 0, 0, 0\n",
    "    \n",
    "    com_dict = {}\n",
    "    for i in range(len(data)):\n",
    "        for el in data[i]:\n",
    "            com_dict[el.item()] = i\n",
    "    ordered_com_dict = collections.OrderedDict(sorted(com_dict.items()))\n",
    "\n",
    "    for el in ordered_com_dict:\n",
    "        #print(el)\n",
    "        if ids[el] == 0:\n",
    "            authors[a] = ordered_com_dict[el]\n",
    "            a = a + 1\n",
    "        if ids[el] == 1:\n",
    "            fields[f] = ordered_com_dict[el]\n",
    "            f = f + 1\n",
    "        if ids[el] == 2:\n",
    "            papers[p] = ordered_com_dict[el]\n",
    "            p = p + 1\n",
    "    dict = {}\n",
    "    for i in range(len(data)):\n",
    "        for el in data[i]:\n",
    "            dict[el.item] = i\n",
    "\n",
    "    dict2 = {}\n",
    "    dict2['author'] = list(authors.values())\n",
    "    dict2['field'] = list(fields.values())\n",
    "    dict2['paper'] = list(papers.values())\n",
    "\n",
    "    with open('com_dict_LPA_ACM.txt', 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(dict2))\n",
    "    name = 'com_dict_LPA_ACM.txt'\n",
    "    return name\n",
    "        \n",
    "def get_com_LOUVAIN_ACM(hg):\n",
    "    g = dgl.to_homogeneous(hg, store_type=True)\n",
    "    nxg = g.to_networkx(node_attrs=['_ID', '_TYPE'], edge_attrs=['_ID', '_TYPE'])\n",
    "    n = nxg.to_undirected()\n",
    "    G2 = nx.Graph(n)\n",
    "    d = community.louvain_communities(G2)\n",
    "    ids = nx.get_node_attributes(nxg, \"_TYPE\")\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(d)):\n",
    "        data.append(torch.Tensor(list(list(d)[i])).to(torch.int64))\n",
    "    print(data)\n",
    "\n",
    "    print(len(data))\n",
    "    authors = {}\n",
    "    papers = {}\n",
    "    fields = {}\n",
    "\n",
    "    a,p,f = 0, 0, 0\n",
    "    com_dict = {}\n",
    "    for i in range(len(data)):\n",
    "        for el in data[i]:\n",
    "            com_dict[el.item()] = i\n",
    "    ordered_com_dict = collections.OrderedDict(sorted(com_dict.items()))\n",
    "\n",
    "\n",
    "\n",
    "    for el in ordered_com_dict:\n",
    "        #print(el)\n",
    "        if ids[el] == 0:\n",
    "            authors[a] = ordered_com_dict[el]\n",
    "            a = a + 1\n",
    "        if ids[el] == 1:\n",
    "            fields[f] = ordered_com_dict[el]\n",
    "            f = f + 1\n",
    "        if ids[el] == 2:\n",
    "            papers[p] = ordered_com_dict[el]\n",
    "            p = p + 1\n",
    "\n",
    "    dict2 = {}\n",
    "    dict2['author'] = list(authors.values())\n",
    "    dict2['field'] = list(fields.values())\n",
    "    dict2['paper'] = list(papers.values())\n",
    "\n",
    "    with open('com_dict_Louvain_ACM.txt', 'w') as convert_file:\n",
    "        convert_file.write(json.dumps(dict2))\n",
    "    name = 'com_dict_Louvain_ACM.txt'\n",
    "    return name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
