{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b45601ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2566987f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "%run utils.ipynb\n",
    "%run model.ipynb\n",
    "%run communities.ipynb\n",
    "%run data.ipynb\n",
    "%run node_embedding.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b252124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#load the dataset and add node_degree to node features\n",
    "def load_and_process(db):\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    DATASET = {\n",
    "        'acm': ACMDataset(),\n",
    "        'imdb': IMDbDataset(),\n",
    "        'dblp': DBLPFourAreaDataset()\n",
    "    }\n",
    "\n",
    "    set_random_seed(1)\n",
    "    data = DATASET[db]\n",
    "    g = data[0]\n",
    "    #add_triangle_count2_imdb(g)\n",
    "    if data == DATASET['dblp']:\n",
    "        print(\"DBLP Dataset\")\n",
    "        #dict1,dict2 = get_community_DBLP(g)\n",
    "        #embedding_community2_DBLP(g,dict1,dict2)\n",
    "        #g,e = embedding_community_DBLP(g)\n",
    "        #add_triangle_count_author_dblp(g)\n",
    "        #add_triangle_count_APA_dblp(g)\n",
    "        #add_triangle_count_APCPA_dblp(g)\n",
    "        #add_triangle_count_APTPA_dblp(g)\n",
    "        #get_LocalClusteringCoeff_dblp(g)\n",
    "        #add_degree_feat_dblp(g)\n",
    "        #add_pageRank_dblp(g)\n",
    "        #fastRP_emb(g)\n",
    "    elif data == DATASET['acm']:\n",
    "        print(\"ACM Dataset\")\n",
    "        #g = add_triangle_count_meta_acm(g)\n",
    "        g = RW_emb_ACM(g,2)\n",
    "        #g = LPE_emb_ACM(g,2)\n",
    "    elif data == DATASET['imdb']:\n",
    "        print(\"IMDb Dataset\")\n",
    "        #embedding_community_IMDb(g)\n",
    "        #add_triangle_count_actor_imdb(g)\n",
    "        #add_triangle_count_MAM_imdb(g)\n",
    "        #add_triangle_count_DMAMD_imdb(g)\n",
    "        #add_degree_feat_imdb(g)\n",
    "        #add_pageRank_imdb(g)\n",
    "        #add_triangle_count_actorMovie_imdb(g)\n",
    "        #get_LocalClusteringCoeff_imdb(g)\n",
    "        g = RW_emb_IMDb(g,2)\n",
    "        g = get_degree_imdb_final(g)\n",
    "    return data,g\n",
    "\n",
    "feat = \"feat\"\n",
    "\n",
    "def train(data,g):\n",
    "    import ast\n",
    "    mlflow.set_experiment(\"IMDb_Deg_RW\")\n",
    "    experiment = mlflow.get_experiment_by_name(\"experiment name\")\n",
    "    best_val_loss = 1000\n",
    "    patience = 100\n",
    "    trigger_times = 0\n",
    "    #node type to predict\n",
    "    predict_ntype = data.predict_ntype\n",
    "    #dictionary containing node type and features\n",
    "    features = {ntype: g.nodes[ntype].data[feat] for ntype in g.ntypes}\n",
    "    #lists containing labels, train-mask,val_mask and test-mask\n",
    "    labels = g.nodes[predict_ntype].data['label']\n",
    "    train_mask = g.nodes[predict_ntype].data['train_mask']\n",
    "    val_mask = g.nodes[predict_ntype].data['val_mask']\n",
    "    test_mask = g.nodes[predict_ntype].data['test_mask']\n",
    "    \n",
    "    \n",
    "    if data.name == \"DBLP_four_area\":\n",
    "        #get_com_LPA_DBLP(g)\n",
    "        #get_com_LOUVAIN_DBLP(g)\n",
    "        #get_com_LPA_DBLP_APCPA(g)\n",
    "        #get_com_Louvain_DBLP(g)\n",
    "        #get_com_Lpa_DBLP(g)\n",
    "        get_com_Leiden_DBLP(g)\n",
    "        com_dict, num_com, com_dim_emb = get_com_info_DBLP() \n",
    "        \n",
    "    if data.name == \"imdb\":\n",
    "        #get_com_LPA_IMDb(g)\n",
    "        #get_com_LOUVAIN_IMDb(g)\n",
    "        #get_com_LPA_IMDb_MDM(g)\n",
    "        #get_com_LPA_IMDb(g)\n",
    "        get_com_Leiden_IMDb(g)\n",
    "        com_dict, num_com, com_dim_emb = get_com_info_IMDb()\n",
    "        \n",
    "    if data.name == \"ACM\":\n",
    "        #get_com_LPA_ACM(g)\n",
    "        #get_com_Leiden_ACM(g)\n",
    "        get_com_Louvain_ACM(g)  \n",
    "        com_dict, num_com, com_dim_emb = get_com_info_ACM()\n",
    "\n",
    "        \n",
    "    with mlflow.start_run():\n",
    "            #initialization of HGT model\n",
    "        \n",
    "        model = HGT(\n",
    "            {ntype: g.nodes[ntype].data[feat].shape[1] for ntype in g.ntypes},\n",
    "            256, data.num_classes, 8, g.ntypes, g.canonical_etypes,\n",
    "            predict_ntype, 3, num_com, com_dim_emb, 0.5\n",
    "        )\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters())\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer, 0.005, total_steps=1000)\n",
    "        metrics = 'Epoch {:d} | Train Loss {:.4f} | Train Micro-F1 {:.4f} | Train Macro-F1 {:.4f}' \\\n",
    "                    ' | Val Micro-F1 {:.4f} | Val Macro-F1 {:.4f}' \n",
    "        #CHANGE       \n",
    "        warnings.filterwarnings('ignore', 'Setting attributes on ParameterDict is not supported')\n",
    "        epochs = 1000\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            # forward propagation by using all nodes\n",
    "            # reading the data from the file\n",
    "            logits = model(g,features,com_dict)\n",
    "            #compute loss\n",
    "            loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "            valid_loss = F.cross_entropy(logits[val_mask], labels[val_mask])\n",
    "            # backward propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            #Total norm of the parameter gradients (viewed as a single vector).\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            #Get the train scores as (microf1,macrof1)\n",
    "            #print(emb(torch.LongTensor([0])))\n",
    "            train_scores = micro_macro_f1_score(logits[train_mask], labels[train_mask])\n",
    "            #Get the val scores as ((microf1,macrof1),val_loss)\n",
    "            val_scores = evaluate(model, g, features, labels, val_mask, micro_macro_f1_score,com_dict)\n",
    "            # Early stopping\n",
    "            print(\"------------------\")\n",
    "            print('The current validation loss:', valid_loss.item())\n",
    "            \n",
    "            if valid_loss > best_val_loss:\n",
    "                trigger_times += 1\n",
    "                print('trigger times:', trigger_times)\n",
    "\n",
    "                if trigger_times >= patience:\n",
    "                    print('Early stopping!\\nStart to test process.')\n",
    "                    break\n",
    "                    print('Early stopping!\\nStart to test process.')\n",
    "                    \n",
    "            else:\n",
    "                print('trigger times: 0')\n",
    "                trigger_times = 0\n",
    "                #save the best model\n",
    "                torch.save(model.state_dict(), 'best-model-parameters.pt')\n",
    "                #save the last validation loss aka the best validation loss\n",
    "                best_val_loss = valid_loss.item()\n",
    "                #save the epoch during the best validation loss\n",
    "                the_last_epoch = epoch\n",
    "                #save the best \n",
    "                best_train_score = train_scores\n",
    "                best_val_score = val_scores[0]\n",
    "                #best_test = test_scores\n",
    "                \n",
    "            print(metrics.format(epoch, loss.item(), *train_scores, *val_scores[0]))\n",
    "\n",
    "        #load the best model\n",
    "        model.load_state_dict(torch.load('best-model-parameters.pt', map_location='cpu'))\n",
    "        #testing\n",
    "        test_scores, loss = evaluate(model, g, features, labels, test_mask, micro_macro_f1_score, com_dict)\n",
    "        print('Test Micro-F1 {:.4f} | Test Macro-F1 {:.4f}'.format(*test_scores))\n",
    "        mlflow.log_param(\"epoch\", epochs)\n",
    "        mlflow.log_param(\"stop_at_epoch\", epoch)\n",
    "        mlflow.log_param(\"best_at_epoch\", the_last_epoch)\n",
    "        mlflow.log_metric(\"loss_test\", loss)\n",
    "        mlflow.log_metric(\"loss_val\", best_val_loss)\n",
    "        mlflow.log_metric(\"train_Micro_f1\", best_train_score[0])\n",
    "        mlflow.log_metric(\"train_Macro_f1\", best_train_score[1])\n",
    "        mlflow.log_metric(\"val_Micro_f1\", best_val_score[0])\n",
    "        mlflow.log_metric(\"val_Macro_f1\", best_val_score[1])\n",
    "        mlflow.log_metric(\"test_Micro_f1\",test_scores[0])\n",
    "        mlflow.log_metric(\"test_Macro_f1\", test_scores[1])\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "    return model\n",
    "        \n",
    "\n",
    "@torch.no_grad()\n",
    "#return a pair (F1_score, loss)\n",
    "def evaluate(model, g, features, labels, mask, score, com_dict):\n",
    "    model.eval()\n",
    "    logits = model(g, features, com_dict)\n",
    "    loss = F.cross_entropy(logits[mask], labels[mask])\n",
    "    return score(logits[mask], labels[mask]), loss\n",
    "\n",
    "def get_best_model(data,g):\n",
    "    predict_ntype = data.predict_ntype\n",
    "    model = HGT(\n",
    "            {ntype: g.nodes[ntype].data[feat].shape[1] for ntype in g.ntypes},\n",
    "            256, data.num_classes, 8, g.ntypes, g.canonical_etypes,\n",
    "            predict_ntype, 3, 0.5\n",
    "        )\n",
    "    \n",
    "    best = model.load_state_dict(torch.load('best-model-parameters.pt'))\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adf59c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "IMDb Dataset\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 5.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 5.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 3.]])\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/02/03 17:11:05 INFO mlflow.tracking.fluent: Experiment with name 'IMDb_Deg_RW' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "The current validation loss: 1.1912922859191895\n",
      "trigger times: 0\n",
      "Epoch 0 | Train Loss 1.1877 | Train Micro-F1 0.3150 | Train Macro-F1 0.3080 | Val Micro-F1 0.3825 | Val Macro-F1 0.2031\n",
      "------------------\n",
      "The current validation loss: 1.1585509777069092\n",
      "trigger times: 0\n",
      "Epoch 1 | Train Loss 1.1635 | Train Micro-F1 0.3650 | Train Macro-F1 0.2696 | Val Micro-F1 0.3900 | Val Macro-F1 0.2551\n",
      "------------------\n",
      "The current validation loss: 1.1759964227676392\n",
      "trigger times: 1\n",
      "Epoch 2 | Train Loss 1.1337 | Train Micro-F1 0.3750 | Train Macro-F1 0.2925 | Val Micro-F1 0.3850 | Val Macro-F1 0.2954\n",
      "------------------\n",
      "The current validation loss: 1.1306582689285278\n",
      "trigger times: 0\n",
      "Epoch 3 | Train Loss 1.0954 | Train Micro-F1 0.3925 | Train Macro-F1 0.3601 | Val Micro-F1 0.4000 | Val Macro-F1 0.3964\n",
      "------------------\n",
      "The current validation loss: 1.1750876903533936\n",
      "trigger times: 1\n",
      "Epoch 4 | Train Loss 1.0749 | Train Micro-F1 0.4375 | Train Macro-F1 0.4368 | Val Micro-F1 0.4100 | Val Macro-F1 0.4099\n",
      "------------------\n",
      "The current validation loss: 1.1552040576934814\n",
      "trigger times: 2\n",
      "Epoch 5 | Train Loss 1.0707 | Train Micro-F1 0.4000 | Train Macro-F1 0.3987 | Val Micro-F1 0.4275 | Val Macro-F1 0.4221\n",
      "------------------\n",
      "The current validation loss: 1.149153709411621\n",
      "trigger times: 3\n",
      "Epoch 6 | Train Loss 1.0625 | Train Micro-F1 0.4050 | Train Macro-F1 0.4006 | Val Micro-F1 0.4225 | Val Macro-F1 0.4078\n",
      "------------------\n",
      "The current validation loss: 1.136117935180664\n",
      "trigger times: 4\n",
      "Epoch 7 | Train Loss 1.0572 | Train Micro-F1 0.4400 | Train Macro-F1 0.4353 | Val Micro-F1 0.4325 | Val Macro-F1 0.3908\n",
      "------------------\n",
      "The current validation loss: 1.1029767990112305\n",
      "trigger times: 0\n",
      "Epoch 8 | Train Loss 1.0190 | Train Micro-F1 0.4775 | Train Macro-F1 0.4572 | Val Micro-F1 0.4300 | Val Macro-F1 0.3897\n",
      "------------------\n",
      "The current validation loss: 1.0963430404663086\n",
      "trigger times: 0\n",
      "Epoch 9 | Train Loss 1.0303 | Train Micro-F1 0.4575 | Train Macro-F1 0.4367 | Val Micro-F1 0.4225 | Val Macro-F1 0.3885\n",
      "------------------\n",
      "The current validation loss: 1.1145105361938477\n",
      "trigger times: 1\n",
      "Epoch 10 | Train Loss 1.0215 | Train Micro-F1 0.4475 | Train Macro-F1 0.4099 | Val Micro-F1 0.4250 | Val Macro-F1 0.4009\n",
      "------------------\n",
      "The current validation loss: 1.1047884225845337\n",
      "trigger times: 2\n",
      "Epoch 11 | Train Loss 0.9795 | Train Micro-F1 0.5325 | Train Macro-F1 0.5140 | Val Micro-F1 0.4300 | Val Macro-F1 0.4122\n",
      "------------------\n",
      "The current validation loss: 1.1016554832458496\n",
      "trigger times: 3\n",
      "Epoch 12 | Train Loss 0.9823 | Train Micro-F1 0.5325 | Train Macro-F1 0.5286 | Val Micro-F1 0.4275 | Val Macro-F1 0.4129\n",
      "------------------\n",
      "The current validation loss: 1.0988976955413818\n",
      "trigger times: 4\n",
      "Epoch 13 | Train Loss 0.9583 | Train Micro-F1 0.5275 | Train Macro-F1 0.5225 | Val Micro-F1 0.4075 | Val Macro-F1 0.3922\n",
      "------------------\n",
      "The current validation loss: 1.0978530645370483\n",
      "trigger times: 5\n",
      "Epoch 14 | Train Loss 0.9538 | Train Micro-F1 0.5200 | Train Macro-F1 0.5170 | Val Micro-F1 0.4075 | Val Macro-F1 0.3950\n",
      "------------------\n",
      "The current validation loss: 1.1295515298843384\n",
      "trigger times: 6\n",
      "Epoch 15 | Train Loss 0.9299 | Train Micro-F1 0.5325 | Train Macro-F1 0.5284 | Val Micro-F1 0.4275 | Val Macro-F1 0.4168\n",
      "------------------\n",
      "The current validation loss: 1.106105089187622\n",
      "trigger times: 7\n",
      "Epoch 16 | Train Loss 0.9438 | Train Micro-F1 0.5575 | Train Macro-F1 0.5520 | Val Micro-F1 0.4450 | Val Macro-F1 0.4337\n",
      "------------------\n",
      "The current validation loss: 1.1069483757019043\n",
      "trigger times: 8\n",
      "Epoch 17 | Train Loss 0.9095 | Train Micro-F1 0.5925 | Train Macro-F1 0.5861 | Val Micro-F1 0.4650 | Val Macro-F1 0.4429\n",
      "------------------\n",
      "The current validation loss: 1.096082329750061\n",
      "trigger times: 0\n",
      "Epoch 18 | Train Loss 0.9070 | Train Micro-F1 0.6125 | Train Macro-F1 0.6112 | Val Micro-F1 0.4725 | Val Macro-F1 0.4488\n",
      "------------------\n",
      "The current validation loss: 1.0969065427780151\n",
      "trigger times: 1\n",
      "Epoch 19 | Train Loss 0.8749 | Train Micro-F1 0.6175 | Train Macro-F1 0.6104 | Val Micro-F1 0.4775 | Val Macro-F1 0.4538\n",
      "------------------\n",
      "The current validation loss: 1.1024470329284668\n",
      "trigger times: 2\n",
      "Epoch 20 | Train Loss 0.8650 | Train Micro-F1 0.6475 | Train Macro-F1 0.6368 | Val Micro-F1 0.4750 | Val Macro-F1 0.4546\n",
      "------------------\n",
      "The current validation loss: 1.1348216533660889\n",
      "trigger times: 3\n",
      "Epoch 21 | Train Loss 0.8381 | Train Micro-F1 0.6450 | Train Macro-F1 0.6384 | Val Micro-F1 0.4650 | Val Macro-F1 0.4512\n",
      "------------------\n",
      "The current validation loss: 1.1021902561187744\n",
      "trigger times: 4\n",
      "Epoch 22 | Train Loss 0.8129 | Train Micro-F1 0.6675 | Train Macro-F1 0.6634 | Val Micro-F1 0.4550 | Val Macro-F1 0.4470\n",
      "------------------\n",
      "The current validation loss: 1.0921070575714111\n",
      "trigger times: 0\n",
      "Epoch 23 | Train Loss 0.7999 | Train Micro-F1 0.6925 | Train Macro-F1 0.6887 | Val Micro-F1 0.4575 | Val Macro-F1 0.4521\n",
      "------------------\n",
      "The current validation loss: 1.1040762662887573\n",
      "trigger times: 1\n",
      "Epoch 24 | Train Loss 0.7868 | Train Micro-F1 0.6700 | Train Macro-F1 0.6647 | Val Micro-F1 0.4600 | Val Macro-F1 0.4548\n",
      "------------------\n",
      "The current validation loss: 1.111802339553833\n",
      "trigger times: 2\n",
      "Epoch 25 | Train Loss 0.7684 | Train Micro-F1 0.7125 | Train Macro-F1 0.7111 | Val Micro-F1 0.4825 | Val Macro-F1 0.4724\n",
      "------------------\n",
      "The current validation loss: 1.0805482864379883\n",
      "trigger times: 0\n",
      "Epoch 26 | Train Loss 0.7323 | Train Micro-F1 0.7250 | Train Macro-F1 0.7246 | Val Micro-F1 0.4925 | Val Macro-F1 0.4755\n",
      "------------------\n",
      "The current validation loss: 1.0632060766220093\n",
      "trigger times: 0\n",
      "Epoch 27 | Train Loss 0.7172 | Train Micro-F1 0.7375 | Train Macro-F1 0.7375 | Val Micro-F1 0.5025 | Val Macro-F1 0.4804\n",
      "------------------\n",
      "The current validation loss: 1.0610942840576172\n",
      "trigger times: 0\n",
      "Epoch 28 | Train Loss 0.6800 | Train Micro-F1 0.7650 | Train Macro-F1 0.7550 | Val Micro-F1 0.5000 | Val Macro-F1 0.4781\n",
      "------------------\n",
      "The current validation loss: 1.0902138948440552\n",
      "trigger times: 1\n",
      "Epoch 29 | Train Loss 0.6510 | Train Micro-F1 0.7700 | Train Macro-F1 0.7646 | Val Micro-F1 0.5000 | Val Macro-F1 0.4846\n",
      "------------------\n",
      "The current validation loss: 1.0516979694366455\n",
      "trigger times: 0\n",
      "Epoch 30 | Train Loss 0.6265 | Train Micro-F1 0.8100 | Train Macro-F1 0.8075 | Val Micro-F1 0.4925 | Val Macro-F1 0.4834\n",
      "------------------\n",
      "The current validation loss: 1.087423324584961\n",
      "trigger times: 1\n",
      "Epoch 31 | Train Loss 0.5934 | Train Micro-F1 0.8250 | Train Macro-F1 0.8244 | Val Micro-F1 0.5000 | Val Macro-F1 0.4956\n",
      "------------------\n",
      "The current validation loss: 1.0697447061538696\n",
      "trigger times: 2\n",
      "Epoch 32 | Train Loss 0.5706 | Train Micro-F1 0.8275 | Train Macro-F1 0.8254 | Val Micro-F1 0.4925 | Val Macro-F1 0.4880\n",
      "------------------\n",
      "The current validation loss: 1.0715930461883545\n",
      "trigger times: 3\n",
      "Epoch 33 | Train Loss 0.5254 | Train Micro-F1 0.8425 | Train Macro-F1 0.8414 | Val Micro-F1 0.5025 | Val Macro-F1 0.4956\n",
      "------------------\n",
      "The current validation loss: 1.076440453529358\n",
      "trigger times: 4\n",
      "Epoch 34 | Train Loss 0.5186 | Train Micro-F1 0.8425 | Train Macro-F1 0.8403 | Val Micro-F1 0.5125 | Val Macro-F1 0.5020\n",
      "------------------\n",
      "The current validation loss: 1.0687289237976074\n",
      "trigger times: 5\n",
      "Epoch 35 | Train Loss 0.4780 | Train Micro-F1 0.8650 | Train Macro-F1 0.8642 | Val Micro-F1 0.5200 | Val Macro-F1 0.5065\n",
      "------------------\n",
      "The current validation loss: 1.089145541191101\n",
      "trigger times: 6\n",
      "Epoch 36 | Train Loss 0.4377 | Train Micro-F1 0.8850 | Train Macro-F1 0.8845 | Val Micro-F1 0.5300 | Val Macro-F1 0.5188\n",
      "------------------\n",
      "The current validation loss: 1.0801827907562256\n",
      "trigger times: 7\n",
      "Epoch 37 | Train Loss 0.3939 | Train Micro-F1 0.9075 | Train Macro-F1 0.9061 | Val Micro-F1 0.5325 | Val Macro-F1 0.5267\n",
      "------------------\n",
      "The current validation loss: 1.104878306388855\n",
      "trigger times: 8\n",
      "Epoch 38 | Train Loss 0.3843 | Train Micro-F1 0.9025 | Train Macro-F1 0.9017 | Val Micro-F1 0.5300 | Val Macro-F1 0.5209\n",
      "------------------\n",
      "The current validation loss: 1.095949411392212\n",
      "trigger times: 9\n",
      "Epoch 39 | Train Loss 0.3534 | Train Micro-F1 0.9075 | Train Macro-F1 0.9071 | Val Micro-F1 0.5225 | Val Macro-F1 0.5121\n",
      "------------------\n",
      "The current validation loss: 1.1010262966156006\n",
      "trigger times: 10\n",
      "Epoch 40 | Train Loss 0.3086 | Train Micro-F1 0.9350 | Train Macro-F1 0.9344 | Val Micro-F1 0.5300 | Val Macro-F1 0.5215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "The current validation loss: 1.1253962516784668\n",
      "trigger times: 11\n",
      "Epoch 41 | Train Loss 0.2960 | Train Micro-F1 0.9350 | Train Macro-F1 0.9348 | Val Micro-F1 0.5400 | Val Macro-F1 0.5323\n",
      "------------------\n",
      "The current validation loss: 1.1036688089370728\n",
      "trigger times: 12\n",
      "Epoch 42 | Train Loss 0.2835 | Train Micro-F1 0.9275 | Train Macro-F1 0.9276 | Val Micro-F1 0.5375 | Val Macro-F1 0.5270\n",
      "------------------\n",
      "The current validation loss: 1.1451374292373657\n",
      "trigger times: 13\n",
      "Epoch 43 | Train Loss 0.2372 | Train Micro-F1 0.9525 | Train Macro-F1 0.9527 | Val Micro-F1 0.5325 | Val Macro-F1 0.5201\n",
      "------------------\n",
      "The current validation loss: 1.150059461593628\n",
      "trigger times: 14\n",
      "Epoch 44 | Train Loss 0.2193 | Train Micro-F1 0.9475 | Train Macro-F1 0.9476 | Val Micro-F1 0.5350 | Val Macro-F1 0.5274\n",
      "------------------\n",
      "The current validation loss: 1.1894844770431519\n",
      "trigger times: 15\n",
      "Epoch 45 | Train Loss 0.2045 | Train Micro-F1 0.9625 | Train Macro-F1 0.9621 | Val Micro-F1 0.5350 | Val Macro-F1 0.5309\n",
      "------------------\n",
      "The current validation loss: 1.1701395511627197\n",
      "trigger times: 16\n",
      "Epoch 46 | Train Loss 0.1825 | Train Micro-F1 0.9525 | Train Macro-F1 0.9520 | Val Micro-F1 0.5400 | Val Macro-F1 0.5351\n",
      "------------------\n",
      "The current validation loss: 1.2426613569259644\n",
      "trigger times: 17\n",
      "Epoch 47 | Train Loss 0.1580 | Train Micro-F1 0.9700 | Train Macro-F1 0.9702 | Val Micro-F1 0.5450 | Val Macro-F1 0.5346\n",
      "------------------\n",
      "The current validation loss: 1.2700161933898926\n",
      "trigger times: 18\n",
      "Epoch 48 | Train Loss 0.1482 | Train Micro-F1 0.9725 | Train Macro-F1 0.9729 | Val Micro-F1 0.5450 | Val Macro-F1 0.5346\n",
      "------------------\n",
      "The current validation loss: 1.284558892250061\n",
      "trigger times: 19\n",
      "Epoch 49 | Train Loss 0.1310 | Train Micro-F1 0.9825 | Train Macro-F1 0.9826 | Val Micro-F1 0.5500 | Val Macro-F1 0.5445\n",
      "------------------\n",
      "The current validation loss: 1.3386878967285156\n",
      "trigger times: 20\n",
      "Epoch 50 | Train Loss 0.1060 | Train Micro-F1 0.9850 | Train Macro-F1 0.9852 | Val Micro-F1 0.5400 | Val Macro-F1 0.5355\n",
      "------------------\n",
      "The current validation loss: 1.381373405456543\n",
      "trigger times: 21\n",
      "Epoch 51 | Train Loss 0.0929 | Train Micro-F1 0.9850 | Train Macro-F1 0.9849 | Val Micro-F1 0.5325 | Val Macro-F1 0.5259\n",
      "------------------\n",
      "The current validation loss: 1.4412510395050049\n",
      "trigger times: 22\n",
      "Epoch 52 | Train Loss 0.0795 | Train Micro-F1 0.9825 | Train Macro-F1 0.9821 | Val Micro-F1 0.5275 | Val Macro-F1 0.5175\n",
      "------------------\n",
      "The current validation loss: 1.5009161233901978\n",
      "trigger times: 23\n",
      "Epoch 53 | Train Loss 0.0651 | Train Micro-F1 0.9850 | Train Macro-F1 0.9850 | Val Micro-F1 0.5525 | Val Macro-F1 0.5437\n",
      "------------------\n",
      "The current validation loss: 1.524375557899475\n",
      "trigger times: 24\n",
      "Epoch 54 | Train Loss 0.0540 | Train Micro-F1 0.9925 | Train Macro-F1 0.9927 | Val Micro-F1 0.5425 | Val Macro-F1 0.5363\n",
      "------------------\n",
      "The current validation loss: 1.6086605787277222\n",
      "trigger times: 25\n",
      "Epoch 55 | Train Loss 0.0426 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5275 | Val Macro-F1 0.5202\n",
      "------------------\n",
      "The current validation loss: 1.6782770156860352\n",
      "trigger times: 26\n",
      "Epoch 56 | Train Loss 0.0373 | Train Micro-F1 0.9950 | Train Macro-F1 0.9950 | Val Micro-F1 0.5275 | Val Macro-F1 0.5194\n",
      "------------------\n",
      "The current validation loss: 1.776106357574463\n",
      "trigger times: 27\n",
      "Epoch 57 | Train Loss 0.0311 | Train Micro-F1 0.9950 | Train Macro-F1 0.9953 | Val Micro-F1 0.5275 | Val Macro-F1 0.5201\n",
      "------------------\n",
      "The current validation loss: 1.8250977993011475\n",
      "trigger times: 28\n",
      "Epoch 58 | Train Loss 0.0232 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5250 | Val Macro-F1 0.5186\n",
      "------------------\n",
      "The current validation loss: 1.9234358072280884\n",
      "trigger times: 29\n",
      "Epoch 59 | Train Loss 0.0211 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5350 | Val Macro-F1 0.5280\n",
      "------------------\n",
      "The current validation loss: 1.9983398914337158\n",
      "trigger times: 30\n",
      "Epoch 60 | Train Loss 0.0188 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5100 | Val Macro-F1 0.5020\n",
      "------------------\n",
      "The current validation loss: 2.0850799083709717\n",
      "trigger times: 31\n",
      "Epoch 61 | Train Loss 0.0133 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5175 | Val Macro-F1 0.5077\n",
      "------------------\n",
      "The current validation loss: 2.2349119186401367\n",
      "trigger times: 32\n",
      "Epoch 62 | Train Loss 0.0098 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5125 | Val Macro-F1 0.5026\n",
      "------------------\n",
      "The current validation loss: 2.386385917663574\n",
      "trigger times: 33\n",
      "Epoch 63 | Train Loss 0.0092 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5325 | Val Macro-F1 0.5260\n",
      "------------------\n",
      "The current validation loss: 2.3772149085998535\n",
      "trigger times: 34\n",
      "Epoch 64 | Train Loss 0.0066 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5425 | Val Macro-F1 0.5387\n",
      "------------------\n",
      "The current validation loss: 2.4522902965545654\n",
      "trigger times: 35\n",
      "Epoch 65 | Train Loss 0.0084 | Train Micro-F1 0.9975 | Train Macro-F1 0.9975 | Val Micro-F1 0.5375 | Val Macro-F1 0.5323\n",
      "------------------\n",
      "The current validation loss: 2.556861639022827\n",
      "trigger times: 36\n",
      "Epoch 66 | Train Loss 0.0057 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5475 | Val Macro-F1 0.5392\n",
      "------------------\n",
      "The current validation loss: 2.6305952072143555\n",
      "trigger times: 37\n",
      "Epoch 67 | Train Loss 0.0056 | Train Micro-F1 0.9975 | Train Macro-F1 0.9975 | Val Micro-F1 0.5375 | Val Macro-F1 0.5314\n",
      "------------------\n",
      "The current validation loss: 2.7332754135131836\n",
      "trigger times: 38\n",
      "Epoch 68 | Train Loss 0.0031 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5500 | Val Macro-F1 0.5475\n",
      "------------------\n",
      "The current validation loss: 2.77211332321167\n",
      "trigger times: 39\n",
      "Epoch 69 | Train Loss 0.0023 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5375 | Val Macro-F1 0.5338\n",
      "------------------\n",
      "The current validation loss: 2.887557029724121\n",
      "trigger times: 40\n",
      "Epoch 70 | Train Loss 0.0019 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5425 | Val Macro-F1 0.5363\n",
      "------------------\n",
      "The current validation loss: 2.949223518371582\n",
      "trigger times: 41\n",
      "Epoch 71 | Train Loss 0.0016 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5400 | Val Macro-F1 0.5353\n",
      "------------------\n",
      "The current validation loss: 3.062741279602051\n",
      "trigger times: 42\n",
      "Epoch 72 | Train Loss 0.0019 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5350 | Val Macro-F1 0.5284\n",
      "------------------\n",
      "The current validation loss: 3.0353238582611084\n",
      "trigger times: 43\n",
      "Epoch 73 | Train Loss 0.0022 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5500 | Val Macro-F1 0.5440\n",
      "------------------\n",
      "The current validation loss: 3.048109769821167\n",
      "trigger times: 44\n",
      "Epoch 74 | Train Loss 0.0089 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5200 | Val Macro-F1 0.5077\n",
      "------------------\n",
      "The current validation loss: 3.298433780670166\n",
      "trigger times: 45\n",
      "Epoch 75 | Train Loss 0.0040 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5325 | Val Macro-F1 0.5237\n",
      "------------------\n",
      "The current validation loss: 3.4063973426818848\n",
      "trigger times: 46\n",
      "Epoch 76 | Train Loss 0.0013 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5350 | Val Macro-F1 0.5300\n",
      "------------------\n",
      "The current validation loss: 3.307572603225708\n",
      "trigger times: 47\n",
      "Epoch 77 | Train Loss 0.0018 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5350 | Val Macro-F1 0.5306\n",
      "------------------\n",
      "The current validation loss: 3.339398145675659\n",
      "trigger times: 48\n",
      "Epoch 78 | Train Loss 0.0021 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5200 | Val Macro-F1 0.5137\n",
      "------------------\n",
      "The current validation loss: 3.5356714725494385\n",
      "trigger times: 49\n",
      "Epoch 79 | Train Loss 0.0017 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5200 | Val Macro-F1 0.5130\n",
      "------------------\n",
      "The current validation loss: 3.6506166458129883\n",
      "trigger times: 50\n",
      "Epoch 80 | Train Loss 0.0074 | Train Micro-F1 0.9950 | Train Macro-F1 0.9951 | Val Micro-F1 0.5350 | Val Macro-F1 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "The current validation loss: 3.5517523288726807\n",
      "trigger times: 51\n",
      "Epoch 81 | Train Loss 0.0031 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5425 | Val Macro-F1 0.5379\n",
      "------------------\n",
      "The current validation loss: 3.6156582832336426\n",
      "trigger times: 52\n",
      "Epoch 82 | Train Loss 0.0010 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5350 | Val Macro-F1 0.5310\n",
      "------------------\n",
      "The current validation loss: 3.722078800201416\n",
      "trigger times: 53\n",
      "Epoch 83 | Train Loss 0.0008 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5275 | Val Macro-F1 0.5239\n",
      "------------------\n",
      "The current validation loss: 3.7819759845733643\n",
      "trigger times: 54\n",
      "Epoch 84 | Train Loss 0.0069 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5350 | Val Macro-F1 0.5329\n",
      "------------------\n",
      "The current validation loss: 3.633305072784424\n",
      "trigger times: 55\n",
      "Epoch 85 | Train Loss 0.0034 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5425 | Val Macro-F1 0.5373\n",
      "------------------\n",
      "The current validation loss: 3.669950246810913\n",
      "trigger times: 56\n",
      "Epoch 86 | Train Loss 0.0022 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5200 | Val Macro-F1 0.5130\n",
      "------------------\n",
      "The current validation loss: 3.888547658920288\n",
      "trigger times: 57\n",
      "Epoch 87 | Train Loss 0.0047 | Train Micro-F1 0.9975 | Train Macro-F1 0.9975 | Val Micro-F1 0.5275 | Val Macro-F1 0.5247\n",
      "------------------\n",
      "The current validation loss: 3.7772951126098633\n",
      "trigger times: 58\n",
      "Epoch 88 | Train Loss 0.0033 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5225 | Val Macro-F1 0.5216\n",
      "------------------\n",
      "The current validation loss: 3.727299690246582\n",
      "trigger times: 59\n",
      "Epoch 89 | Train Loss 0.0051 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5275 | Val Macro-F1 0.5267\n",
      "------------------\n",
      "The current validation loss: 3.679917335510254\n",
      "trigger times: 60\n",
      "Epoch 90 | Train Loss 0.0031 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5250 | Val Macro-F1 0.5187\n",
      "------------------\n",
      "The current validation loss: 4.036293983459473\n",
      "trigger times: 61\n",
      "Epoch 91 | Train Loss 0.0007 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5150 | Val Macro-F1 0.5011\n",
      "------------------\n",
      "The current validation loss: 4.201242923736572\n",
      "trigger times: 62\n",
      "Epoch 92 | Train Loss 0.0200 | Train Micro-F1 0.9900 | Train Macro-F1 0.9905 | Val Micro-F1 0.5275 | Val Macro-F1 0.5185\n",
      "------------------\n",
      "The current validation loss: 4.114589691162109\n",
      "trigger times: 63\n",
      "Epoch 93 | Train Loss 0.0023 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5350 | Val Macro-F1 0.5322\n",
      "------------------\n",
      "The current validation loss: 3.720292329788208\n",
      "trigger times: 64\n",
      "Epoch 94 | Train Loss 0.0085 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5325 | Val Macro-F1 0.5292\n",
      "------------------\n",
      "The current validation loss: 3.6542747020721436\n",
      "trigger times: 65\n",
      "Epoch 95 | Train Loss 0.0024 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5250 | Val Macro-F1 0.5158\n",
      "------------------\n",
      "The current validation loss: 3.888017177581787\n",
      "trigger times: 66\n",
      "Epoch 96 | Train Loss 0.0018 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5125 | Val Macro-F1 0.4945\n",
      "------------------\n",
      "The current validation loss: 4.23411750793457\n",
      "trigger times: 67\n",
      "Epoch 97 | Train Loss 0.0076 | Train Micro-F1 0.9950 | Train Macro-F1 0.9950 | Val Micro-F1 0.5300 | Val Macro-F1 0.5137\n",
      "------------------\n",
      "The current validation loss: 4.127512454986572\n",
      "trigger times: 68\n",
      "Epoch 98 | Train Loss 0.0037 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5350 | Val Macro-F1 0.5231\n",
      "------------------\n",
      "The current validation loss: 3.768414258956909\n",
      "trigger times: 69\n",
      "Epoch 99 | Train Loss 0.0042 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5625 | Val Macro-F1 0.5536\n",
      "------------------\n",
      "The current validation loss: 3.7095086574554443\n",
      "trigger times: 70\n",
      "Epoch 100 | Train Loss 0.0052 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5350 | Val Macro-F1 0.5243\n",
      "------------------\n",
      "The current validation loss: 3.9236159324645996\n",
      "trigger times: 71\n",
      "Epoch 101 | Train Loss 0.0035 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5450 | Val Macro-F1 0.5367\n",
      "------------------\n",
      "The current validation loss: 3.872312307357788\n",
      "trigger times: 72\n",
      "Epoch 102 | Train Loss 0.0099 | Train Micro-F1 0.9950 | Train Macro-F1 0.9950 | Val Micro-F1 0.5475 | Val Macro-F1 0.5408\n",
      "------------------\n",
      "The current validation loss: 3.822582960128784\n",
      "trigger times: 73\n",
      "Epoch 103 | Train Loss 0.0019 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5425 | Val Macro-F1 0.5371\n",
      "------------------\n",
      "The current validation loss: 3.6827664375305176\n",
      "trigger times: 74\n",
      "Epoch 104 | Train Loss 0.0019 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5475 | Val Macro-F1 0.5407\n",
      "------------------\n",
      "The current validation loss: 3.9219319820404053\n",
      "trigger times: 75\n",
      "Epoch 105 | Train Loss 0.0006 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5350 | Val Macro-F1 0.5268\n",
      "------------------\n",
      "The current validation loss: 4.081472873687744\n",
      "trigger times: 76\n",
      "Epoch 106 | Train Loss 0.0026 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5325 | Val Macro-F1 0.5238\n",
      "------------------\n",
      "The current validation loss: 4.063088893890381\n",
      "trigger times: 77\n",
      "Epoch 107 | Train Loss 0.0003 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5275 | Val Macro-F1 0.5208\n",
      "------------------\n",
      "The current validation loss: 4.1114888191223145\n",
      "trigger times: 78\n",
      "Epoch 108 | Train Loss 0.0012 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5200 | Val Macro-F1 0.5113\n",
      "------------------\n",
      "The current validation loss: 4.131580352783203\n",
      "trigger times: 79\n",
      "Epoch 109 | Train Loss 0.0015 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5200 | Val Macro-F1 0.5067\n",
      "------------------\n",
      "The current validation loss: 4.25895357131958\n",
      "trigger times: 80\n",
      "Epoch 110 | Train Loss 0.0018 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5125 | Val Macro-F1 0.5052\n",
      "------------------\n",
      "The current validation loss: 4.164331912994385\n",
      "trigger times: 81\n",
      "Epoch 111 | Train Loss 0.0009 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5150 | Val Macro-F1 0.5096\n",
      "------------------\n",
      "The current validation loss: 4.2227559089660645\n",
      "trigger times: 82\n",
      "Epoch 112 | Train Loss 0.0008 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5150 | Val Macro-F1 0.5113\n",
      "------------------\n",
      "The current validation loss: 4.246187686920166\n",
      "trigger times: 83\n",
      "Epoch 113 | Train Loss 0.0009 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5150 | Val Macro-F1 0.5116\n",
      "------------------\n",
      "The current validation loss: 4.220923900604248\n",
      "trigger times: 84\n",
      "Epoch 114 | Train Loss 0.0003 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5125 | Val Macro-F1 0.5056\n",
      "------------------\n",
      "The current validation loss: 4.27288818359375\n",
      "trigger times: 85\n",
      "Epoch 115 | Train Loss 0.0006 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5125 | Val Macro-F1 0.5044\n",
      "------------------\n",
      "The current validation loss: 4.342817306518555\n",
      "trigger times: 86\n",
      "Epoch 116 | Train Loss 0.0004 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5275 | Val Macro-F1 0.5191\n",
      "------------------\n",
      "The current validation loss: 4.302792072296143\n",
      "trigger times: 87\n",
      "Epoch 117 | Train Loss 0.0004 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5275 | Val Macro-F1 0.5190\n",
      "------------------\n",
      "The current validation loss: 4.307592868804932\n",
      "trigger times: 88\n",
      "Epoch 118 | Train Loss 0.0003 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5325 | Val Macro-F1 0.5224\n",
      "------------------\n",
      "The current validation loss: 4.254261493682861\n",
      "trigger times: 89\n",
      "Epoch 119 | Train Loss 0.0003 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5400 | Val Macro-F1 0.5292\n",
      "------------------\n",
      "The current validation loss: 4.287499904632568\n",
      "trigger times: 90\n",
      "Epoch 120 | Train Loss 0.0038 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5200 | Val Macro-F1 0.4998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "The current validation loss: 4.512793064117432\n",
      "trigger times: 91\n",
      "Epoch 121 | Train Loss 0.0089 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5375 | Val Macro-F1 0.5211\n",
      "------------------\n",
      "The current validation loss: 4.3714752197265625\n",
      "trigger times: 92\n",
      "Epoch 122 | Train Loss 0.0008 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5275 | Val Macro-F1 0.5172\n",
      "------------------\n",
      "The current validation loss: 4.290438175201416\n",
      "trigger times: 93\n",
      "Epoch 123 | Train Loss 0.0002 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5350 | Val Macro-F1 0.5279\n",
      "------------------\n",
      "The current validation loss: 4.159806728363037\n",
      "trigger times: 94\n",
      "Epoch 124 | Train Loss 0.0004 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5350 | Val Macro-F1 0.5310\n",
      "------------------\n",
      "The current validation loss: 4.136074542999268\n",
      "trigger times: 95\n",
      "Epoch 125 | Train Loss 0.0093 | Train Micro-F1 0.9975 | Train Macro-F1 0.9976 | Val Micro-F1 0.5150 | Val Macro-F1 0.5065\n",
      "------------------\n",
      "The current validation loss: 4.24440860748291\n",
      "trigger times: 96\n",
      "Epoch 126 | Train Loss 0.0082 | Train Micro-F1 0.9950 | Train Macro-F1 0.9950 | Val Micro-F1 0.5025 | Val Macro-F1 0.4780\n",
      "------------------\n",
      "The current validation loss: 4.6327223777771\n",
      "trigger times: 97\n",
      "Epoch 127 | Train Loss 0.0484 | Train Micro-F1 0.9925 | Train Macro-F1 0.9926 | Val Micro-F1 0.5100 | Val Macro-F1 0.4797\n",
      "------------------\n",
      "The current validation loss: 4.701986789703369\n",
      "trigger times: 98\n",
      "Epoch 128 | Train Loss 0.0117 | Train Micro-F1 0.9950 | Train Macro-F1 0.9951 | Val Micro-F1 0.5300 | Val Macro-F1 0.5109\n",
      "------------------\n",
      "The current validation loss: 4.204946994781494\n",
      "trigger times: 99\n",
      "Epoch 129 | Train Loss 0.0003 | Train Micro-F1 1.0000 | Train Macro-F1 1.0000 | Val Micro-F1 0.5450 | Val Macro-F1 0.5334\n",
      "------------------\n",
      "The current validation loss: 3.779428482055664\n",
      "trigger times: 100\n",
      "Early stopping!\n",
      "Start to test process.\n",
      "Test Micro-F1 0.4710 | Test Macro-F1 0.4684\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data, g = load_and_process('imdb')\n",
    "    trained = train(data,g)\n",
    "    #best_model = get_best_model(data,g)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbfa9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
